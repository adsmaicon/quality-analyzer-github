[{"url":"https://api.github.com/repos/tensorflow/models/issues/10571","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10571/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10571/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10571/events","html_url":"https://github.com/tensorflow/models/issues/10571","id":1188274549,"node_id":"I_kwDOAwv_Dc5G06F1","number":10571,"title":"inference image preprocessing","user":{"login":"dacquaviva","id":24587407,"node_id":"MDQ6VXNlcjI0NTg3NDA3","avatar_url":"https://avatars.githubusercontent.com/u/24587407?v=4","gravatar_id":"","url":"https://api.github.com/users/dacquaviva","html_url":"https://github.com/dacquaviva","followers_url":"https://api.github.com/users/dacquaviva/followers","following_url":"https://api.github.com/users/dacquaviva/following{/other_user}","gists_url":"https://api.github.com/users/dacquaviva/gists{/gist_id}","starred_url":"https://api.github.com/users/dacquaviva/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dacquaviva/subscriptions","organizations_url":"https://api.github.com/users/dacquaviva/orgs","repos_url":"https://api.github.com/users/dacquaviva/repos","events_url":"https://api.github.com/users/dacquaviva/events{/privacy}","received_events_url":"https://api.github.com/users/dacquaviva/received_events","type":"User","site_admin":false},"labels":[{"id":519009460,"node_id":"MDU6TGFiZWw1MTkwMDk0NjA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:docs","name":"type:docs","color":"e8c25c","default":false,"description":""},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-31T15:35:42Z","updated_at":"2022-03-31T15:35:42Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello all!\r\n\r\nI am using a pretrained Object detection API models ([SSD MobileNet V2 FPNLite 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz).) and I have doubts regarding image preprocessing and output postprocessing, I tried to look up the doc but couldn't find anything about it.\r\n\r\n - When using tensorflow `tf.saved_model.load(path_model)` to make inference using the above mentioned model (SSD MobileNet V2 FPNLite 320x320) do I need to resize my input image to 300x300 and scale it [-1,1] or will the model do it for me?\r\n\r\n- When converting the above mentioned model (SSD MobileNet V2 FPNLite 320x320) to tfLite will the model also resize the image to 300x300 and scale it to [-1,1] or do I need to do it beforehand for example using cv2 and numpy (I tried passing the raw image however I get error therefore I believe I need to do the preprocessing myself).\r\n\r\n- How is tensorflow returning the coordinates [0,1] mapped on the original image resolution (not 300x300 but the original one)? I believe it is saving this information from the tfrecord during training however it would be nice to have a confirmation.\r\n\r\nThanks!\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10571/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10571/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10569","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10569/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10569/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10569/events","html_url":"https://github.com/tensorflow/models/issues/10569","id":1186056814,"node_id":"I_kwDOAwv_Dc5Gscpu","number":10569,"title":"ModuleNotFoundError: No module named 'object_detection.predictors.heads'","user":{"login":"courtney-ann","id":95727276,"node_id":"U_kgDOBbSurA","avatar_url":"https://avatars.githubusercontent.com/u/95727276?v=4","gravatar_id":"","url":"https://api.github.com/users/courtney-ann","html_url":"https://github.com/courtney-ann","followers_url":"https://api.github.com/users/courtney-ann/followers","following_url":"https://api.github.com/users/courtney-ann/following{/other_user}","gists_url":"https://api.github.com/users/courtney-ann/gists{/gist_id}","starred_url":"https://api.github.com/users/courtney-ann/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/courtney-ann/subscriptions","organizations_url":"https://api.github.com/users/courtney-ann/orgs","repos_url":"https://api.github.com/users/courtney-ann/repos","events_url":"https://api.github.com/users/courtney-ann/events{/privacy}","received_events_url":"https://api.github.com/users/courtney-ann/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-30T08:11:01Z","updated_at":"2022-03-30T08:11:10Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Prerequisites\r\n\r\nPlease answer the following questions for yourself before submitting an issue.\r\n\r\n- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2. Yes\r\n- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory) Yes\r\n- [x] I checked to make sure that this issue has not been filed already. Yes\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/research/object_detection/predictors/heads\r\n\r\n## 2. Describe the bug\r\nI am trying to train a model with the following code in Google Colab:\r\n\r\n!python /content/drive/ColabNotebooks/TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_fasterrcnn_resnet --pipeline_config_path=Tensorflow/workspace/models/my_fasterrcnn_resnet/pipeline.config --num_train_steps=1000\r\n\r\nbut I keep getting the error ModuleNotFoundError: No module named 'object_detection.predictors.heads' . I checked the heads folder and found that it was empty so I copied the files from the Github repo but I am still getting the same error. Can someone please help with this issue?\r\n\r\n\r\n\r\n\r\n## 3. Steps to reproduce\r\n\r\nSteps to reproduce the behavior.\r\n\r\n## 4. Expected behavior\r\n\r\nA clear and concise description of what you expected to happen.\r\n\r\n## 5. Additional context\r\n\r\nInclude any logs that would be helpful to diagnose the problem.\r\n\r\n## 6. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device name if the issue happens on a mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n<!-- \r\nCollect system information using our environment capture script.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can also obtain the TensorFlow version with:\r\n\r\n1. TensorFlow 1.0\r\n`python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n\r\n2. TensorFlow 2.0\r\n`python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n-->\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10569/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10569/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10567","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10567/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10567/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10567/events","html_url":"https://github.com/tensorflow/models/issues/10567","id":1184051384,"node_id":"I_kwDOAwv_Dc5GkzC4","number":10567,"title":"TEAMS: Pre-Training questions","user":{"login":"stefan-it","id":20651387,"node_id":"MDQ6VXNlcjIwNjUxMzg3","avatar_url":"https://avatars.githubusercontent.com/u/20651387?v=4","gravatar_id":"","url":"https://api.github.com/users/stefan-it","html_url":"https://github.com/stefan-it","followers_url":"https://api.github.com/users/stefan-it/followers","following_url":"https://api.github.com/users/stefan-it/following{/other_user}","gists_url":"https://api.github.com/users/stefan-it/gists{/gist_id}","starred_url":"https://api.github.com/users/stefan-it/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefan-it/subscriptions","organizations_url":"https://api.github.com/users/stefan-it/orgs","repos_url":"https://api.github.com/users/stefan-it/repos","events_url":"https://api.github.com/users/stefan-it/events{/privacy}","received_events_url":"https://api.github.com/users/stefan-it/received_events","type":"User","site_admin":false},"labels":[{"id":519009460,"node_id":"MDU6TGFiZWw1MTkwMDk0NjA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:docs","name":"type:docs","color":"e8c25c","default":false,"description":""},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2022-03-28T22:11:13Z","updated_at":"2022-03-28T22:38:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI have some questions about the \"Training ELECTRA Augmented with Multi-word Selection\" (TEAMS) implementation:\r\n\r\nAt the moment, there's no section about generating pre-training dataset. I would really like to know if the `create_pretraining.py` script from [here](official/nlp/data/create_pretraining_data.py) can be used (although, ELECTRA has a different masking strategy and e.g. `dupe_factor` could be 1?!). If not, how is it possible to create TFRecords for the TEAMS approach?\r\n\r\nThe pre-training procedure is currently not documented. Looking at another project (e.g. Token Dropping) it seems that `train.py` is missing. So I think one could copy it and simply change the experiment config (see [here](https://github.com/tensorflow/models/blob/master/official/projects/token_dropping/train.py#L27)).\r\n\r\nI'm interesting in pre-training and convert TEAMS model weights to be compatible with Transformers library, so any help regarding to the pre-training data generation would highly be appreciated!","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10567/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10567/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10566","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10566/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10566/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10566/events","html_url":"https://github.com/tensorflow/models/issues/10566","id":1183563431,"node_id":"I_kwDOAwv_Dc5Gi76n","number":10566,"title":"Problem running video_ssl (for the paper Spatiotemporal Contrastive Video Representation Learning)","user":{"login":"alpargun","id":52760747,"node_id":"MDQ6VXNlcjUyNzYwNzQ3","avatar_url":"https://avatars.githubusercontent.com/u/52760747?v=4","gravatar_id":"","url":"https://api.github.com/users/alpargun","html_url":"https://github.com/alpargun","followers_url":"https://api.github.com/users/alpargun/followers","following_url":"https://api.github.com/users/alpargun/following{/other_user}","gists_url":"https://api.github.com/users/alpargun/gists{/gist_id}","starred_url":"https://api.github.com/users/alpargun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpargun/subscriptions","organizations_url":"https://api.github.com/users/alpargun/orgs","repos_url":"https://api.github.com/users/alpargun/repos","events_url":"https://api.github.com/users/alpargun/events{/privacy}","received_events_url":"https://api.github.com/users/alpargun/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false},"assignees":[{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2022-03-28T14:53:47Z","updated_at":"2022-03-30T11:17:34Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Prerequisites\r\n\r\n- [x] I am using the latest TensorFlow Model Garden release and TensorFlow 2.\r\n- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)\r\n- [x] I checked to make sure that this issue has not been filed already.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/tree/master/official/projects/video_ssl\r\n\r\n## 2. Describe the bug and Steps to reproduce\r\n\r\nI am trying to run the project video_ssl for the paper _Spatiotemporal Contrastive Video Representation Learning_. Since there is not an explanation for running the script yet, I am trying from scratch to run the code, passing through errors step by step.\r\n\r\nHere is my command the run the train.py file:\r\n`python train.py --experiment=resnet_imagenet --config_file=configs/experiments/cvrl_pretrain_k600_200ep.yaml --mode=train_and_eval --model_dir=temp/`\r\n\r\n1. --experiment flag is not explained clearly. When I searched for the usage of the same flag in other projects, I saw \"resnet_imagenet\" is used, hence, used it as the --experiment flag and passed through this error. Otherwise, I was getting the error:\r\n\r\n_LookupError: collection {} at position 0 is never registered. Please make sure {} the  and its library is imported and linked to the trainer binary._\r\n\r\nWith \"imagenet_resnet\" as the --experiment flag, I am no longer getting this error.\r\n\r\n2. However, with \"imagenet_resnet\" as the --experiment flag, now I see the error: \r\n_KeyError: \"The key 'resnet_3d' does not exist in <class 'official.vision.configs.backbones.Backbone'>. To extend the existing keys, use `override` with `is_strict` = False.\"_\r\n\r\nIn order to fix this, I added \r\n` is_strict=False`\r\ninside the file _official/modeling/hyperparams/base_config.py_\r\n\r\n3.  After hard-coding this parameter, I am able to move on to a new error:\r\n_ValueError: Please provide a TPU Name to connect to._\r\n\r\nSo, from the config file, _configs/experiments/cvrl_pretrain_k600_200ep.yaml_, I commented out the distribution strategy part as below:\r\n```\r\nruntime:\r\n  #distribution_strategy: 'tpu'\r\n```\r\n\r\n4. Now, I am able to start training as I see the message:\r\n\r\n_INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nI0330 13:10:11.765658 139807751000448 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\r\nI0330 13:10:11.766262 139807751000448 train_utils.py:220] Running default trainer._\r\n\r\nHowever, now I get the error:\r\n\r\n  _File \"/home/alpargun/Desktop/models-2.8.0/official/core/input_reader.py\", line 65, in match_files\r\n    raise ValueError('%s does not match any files.' % input_pattern)\r\nValueError: imagenet-2012-tfrecord/valid* does not match any files.\r\n  In call to configurable 'Trainer' (<class 'official.core.base_trainer.Trainer'>)\r\n  In call to configurable 'create_trainer' (<function create_trainer at 0x7f27150ca820>)_\r\n\r\nHence, it looks like I am currently in the part where I need to supply the data set to be used for train or eval modes.\r\n\r\n\r\nAt this point, I would be very glad if you can add an explanation on how to run the code but I also have 4 specific questions:\r\n\r\n1. How should I assign the --experiment flag? What are the options other than \"resnet_imagenet\" as in this case I believe 3D resnet is required?\r\n2. How can you change the backbone? I already tried changing the model_id and the backbone name through the config file but it seems like they are overwritten somewhere else.\r\n3. Which tf version should be used? There is no information related to the tf version, so I just used the newest one (tf 2.8)\r\n4. How can I supply the data set to be used for train or eval modes? \r\n\r\n\r\n## 3. Expected behavior\r\n\r\nI expected to be able to run the _train.py_ file with an included config file on one of the data sets the paper also uses to test the algorithm to be able to integrate it to my project.\r\n\r\n\r\n\r\n## 4. System information\r\n\r\n- OS Platform and Distribution: (Linux Ubuntu 20.04):\r\n- TensorFlow installed: I used `pip install tensorflow`\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version: 3.8.12\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: GeForce RTX 2080 Ti Rev. A, 11019 MiB\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10566/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10566/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10565","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10565/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10565/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10565/events","html_url":"https://github.com/tensorflow/models/issues/10565","id":1183526036,"node_id":"I_kwDOAwv_Dc5GiyyU","number":10565,"title":"TensorFlow Object Detection training error","user":{"login":"mkaur013","id":102364279,"node_id":"U_kgDOBhn0dw","avatar_url":"https://avatars.githubusercontent.com/u/102364279?v=4","gravatar_id":"","url":"https://api.github.com/users/mkaur013","html_url":"https://github.com/mkaur013","followers_url":"https://api.github.com/users/mkaur013/followers","following_url":"https://api.github.com/users/mkaur013/following{/other_user}","gists_url":"https://api.github.com/users/mkaur013/gists{/gist_id}","starred_url":"https://api.github.com/users/mkaur013/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mkaur013/subscriptions","organizations_url":"https://api.github.com/users/mkaur013/orgs","repos_url":"https://api.github.com/users/mkaur013/repos","events_url":"https://api.github.com/users/mkaur013/events{/privacy}","received_events_url":"https://api.github.com/users/mkaur013/received_events","type":"User","site_admin":false},"labels":[{"id":387356495,"node_id":"MDU6TGFiZWwzODczNTY0OTU=","url":"https://api.github.com/repos/tensorflow/models/labels/stat:awaiting%20response","name":"stat:awaiting response","color":"f4b400","default":false,"description":"Waiting on input from the contributor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-03-28T14:26:10Z","updated_at":"2022-03-30T17:53:39Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello, \r\n\r\nI am training a object detection model \r\nTensorFlow = 2.7.0\r\nIf I use TensorFlow = 2.8.0, then i get error \"No module named 'tensorflow.python.keras.layers.preprocessing'\"\r\nGot below error:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"C:\\Users\\User\\anaconda3\\lib\\threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>>\r\n>>>   File \"C:\\Users\\User\\anaconda3\\lib\\threading.py\", line 926, in _bootstrap_inner\r\n>>>     self.run()\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 170, in _dummy_computation_fn\r\n>>>     return _compute_losses_and_predictions_dicts(model, features, labels,\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\model_lib_v2.py\", line 123, in _compute_losses_and_predictions_dicts\r\n>>>     prediction_dict = model.predict(\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 569, in predict\r\n>>>     if self._feature_extractor.is_keras_model:\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 570, in predict\r\n>>>     feature_maps = self._feature_extractor(preprocessed_inputs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\meta_architectures\\ssd_meta_arch.py\", line 251, in call\r\n>>>     return self._extract_features(inputs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\object_detection\\models\\ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 219, in _extract_features\r\n>>>     image_features = self.classification_backbone(\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\r\n>>>     inputs, training=training, mask=mask)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 246, in call\r\n>>>     outputs = self.convolution_op(inputs, self.kernel)\r\n>>>\r\n>>>   File \"C:\\Users\\User\\Desktop\\ACoBot\\Code\\tfod\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 238, in convolution_op\r\n>>>     name=self.__class__.__name__)\r\n>>>","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10565/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10565/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10563","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10563/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10563/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10563/events","html_url":"https://github.com/tensorflow/models/issues/10563","id":1182522822,"node_id":"I_kwDOAwv_Dc5Ge93G","number":10563,"title":"AttributeError: module 'object_detection.protos.faster_rcnn_pb2' has no attribute 'AttentionPosition' while model_builders is getting imported","user":{"login":"Daremitsu1","id":54842807,"node_id":"MDQ6VXNlcjU0ODQyODA3","avatar_url":"https://avatars.githubusercontent.com/u/54842807?v=4","gravatar_id":"","url":"https://api.github.com/users/Daremitsu1","html_url":"https://github.com/Daremitsu1","followers_url":"https://api.github.com/users/Daremitsu1/followers","following_url":"https://api.github.com/users/Daremitsu1/following{/other_user}","gists_url":"https://api.github.com/users/Daremitsu1/gists{/gist_id}","starred_url":"https://api.github.com/users/Daremitsu1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Daremitsu1/subscriptions","organizations_url":"https://api.github.com/users/Daremitsu1/orgs","repos_url":"https://api.github.com/users/Daremitsu1/repos","events_url":"https://api.github.com/users/Daremitsu1/events{/privacy}","received_events_url":"https://api.github.com/users/Daremitsu1/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-27T13:07:33Z","updated_at":"2022-03-27T13:07:33Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"While trying to run the following code:-\r\n\r\n`import os`\r\n`import tensorflow as tf` \r\n`from object_detection.utils import label_map_util` \r\n`from object_detection.utils import visualization_utils as viz_utils`\r\n`from object_detection.builders import model_builder`\r\n`from object_detection.utils import config_util`\r\n\r\nI am getting the following error:-\r\n```\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nInput In [16], in <cell line: 5>()\r\n      3 from object_detection.utils import label_map_util\r\n      4 from object_detection.utils import visualization_utils as viz_utils\r\n----> 5 from object_detection.builders import model_builder\r\n      6 from object_detection.utils import config_util\r\n\r\nFile ~\\anaconda3\\envs\\anprsys\\lib\\site-packages\\object_detection\\builders\\model_builder.py:36, in <module>\r\n     34 from object_detection.meta_architectures import ssd_meta_arch\r\n     35 from object_detection.models import faster_rcnn_inception_resnet_v2_feature_extractor as frcnn_inc_res\r\n---> 36 from object_detection.models import faster_rcnn_inception_v2_feature_extractor as frcnn_inc_v2\r\n     37 from object_detection.models import faster_rcnn_nas_feature_extractor as frcnn_nas\r\n     38 from object_detection.models import faster_rcnn_pnas_feature_extractor as frcnn_pnas\r\n\r\nFile ~\\anaconda3\\envs\\anprsys\\lib\\site-packages\\object_detection\\meta_architectures\\context_rcnn_meta_arch.py:42, in <module>\r\n     37 from object_detection.utils import tf_version\r\n     39 _UNINITIALIZED_FEATURE_EXTRACTOR = '__uninitialized__'\r\n---> 42 class ContextRCNNMetaArch(faster_rcnn_meta_arch.FasterRCNNMetaArch):\r\n     43   \"\"\"Context R-CNN Meta-architecture definition.\"\"\"\r\n     45   def __init__(self,\r\n     46                is_training,\r\n     47                num_classes,\r\n   (...)\r\n     95                    faster_rcnn_pb2.AttentionPosition.POST_BOX_CLASSIFIER)\r\n     96                ):\r\n\r\nFile ~\\anaconda3\\envs\\anprsys\\lib\\site-packages\\object_detection\\meta_architectures\\context_rcnn_meta_arch.py:95, in ContextRCNNMetaArch()\r\n     42 class ContextRCNNMetaArch(faster_rcnn_meta_arch.FasterRCNNMetaArch):\r\n     43   \"\"\"Context R-CNN Meta-architecture definition.\"\"\"\r\n     45   def __init__(self,\r\n     46                is_training,\r\n     47                num_classes,\r\n     48                image_resizer_fn,\r\n     49                feature_extractor,\r\n     50                number_of_stages,\r\n     51                first_stage_anchor_generator,\r\n     52                first_stage_target_assigner,\r\n     53                first_stage_atrous_rate,\r\n     54                first_stage_box_predictor_arg_scope_fn,\r\n     55                first_stage_box_predictor_kernel_size,\r\n     56                first_stage_box_predictor_depth,\r\n     57                first_stage_minibatch_size,\r\n     58                first_stage_sampler,\r\n     59                first_stage_non_max_suppression_fn,\r\n     60                first_stage_max_proposals,\r\n     61                first_stage_localization_loss_weight,\r\n     62                first_stage_objectness_loss_weight,\r\n     63                crop_and_resize_fn,\r\n     64                initial_crop_size,\r\n     65                maxpool_kernel_size,\r\n     66                maxpool_stride,\r\n     67                second_stage_target_assigner,\r\n     68                second_stage_mask_rcnn_box_predictor,\r\n     69                second_stage_batch_size,\r\n     70                second_stage_sampler,\r\n     71                second_stage_non_max_suppression_fn,\r\n     72                second_stage_score_conversion_fn,\r\n     73                second_stage_localization_loss_weight,\r\n     74                second_stage_classification_loss_weight,\r\n     75                second_stage_classification_loss,\r\n     76                second_stage_mask_prediction_loss_weight=1.0,\r\n     77                hard_example_miner=None,\r\n     78                parallel_iterations=16,\r\n     79                add_summaries=True,\r\n     80                clip_anchors_to_image=False,\r\n     81                use_static_shapes=False,\r\n     82                resize_masks=True,\r\n     83                freeze_batchnorm=False,\r\n     84                return_raw_detections_during_predict=False,\r\n     85                output_final_box_features=False,\r\n     86                output_final_box_rpn_features=False,\r\n     87                attention_bottleneck_dimension=None,\r\n     88                attention_temperature=None,\r\n     89                use_self_attention=False,\r\n     90                use_long_term_attention=True,\r\n     91                self_attention_in_sequence=False,\r\n     92                num_attention_heads=1,\r\n     93                num_attention_layers=1,\r\n     94                attention_position=(\r\n---> 95                    faster_rcnn_pb2.AttentionPosition.POST_BOX_CLASSIFIER)\r\n     96                ):\r\n     97     \"\"\"ContextRCNNMetaArch Constructor.\r\n     98 \r\n     99     Args:\r\n   (...)\r\n    253         grid_anchor_generator.GridAnchorGenerator.\r\n    254     \"\"\"\r\n    255     super(ContextRCNNMetaArch, self).__init__(\r\n    256         is_training,\r\n    257         num_classes,\r\n   (...)\r\n    297         output_final_box_features=output_final_box_features,\r\n    298         output_final_box_rpn_features=output_final_box_rpn_features)\r\n\r\nAttributeError: module 'object_detection.protos.faster_rcnn_pb2' has no attribute 'AttentionPosition'\r\n```\r\n\r\nI went through the context_rcnn_meta_arch.py and seems like the attribute called 'AttentionPosition' is not present.\r\n\r\nI have also `cd models/research ` into `C:\\Users\\USER\\anaconda3\\envs\\anprsys\\Lib\\site-packages\\models\\research\\` and also pasted the protoc.exe and ran` protoc object_detection/protos/*.proto --python_out=.`\r\n\r\nI am using Python version 3.9 with this project(since for Python 3.10 I was getting a sentencepiece error) and my tensorflow version is 2.8.0.\r\n\r\nPlease help regarding this problem.","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10563/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10563/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10562","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10562/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10562/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10562/events","html_url":"https://github.com/tensorflow/models/issues/10562","id":1182521544,"node_id":"I_kwDOAwv_Dc5Ge9jI","number":10562,"title":"VIT: WARNING:absl:Found untraced functions... These functions will not be directly callable after loading.","user":{"login":"exx8","id":8540180,"node_id":"MDQ6VXNlcjg1NDAxODA=","avatar_url":"https://avatars.githubusercontent.com/u/8540180?v=4","gravatar_id":"","url":"https://api.github.com/users/exx8","html_url":"https://github.com/exx8","followers_url":"https://api.github.com/users/exx8/followers","following_url":"https://api.github.com/users/exx8/following{/other_user}","gists_url":"https://api.github.com/users/exx8/gists{/gist_id}","starred_url":"https://api.github.com/users/exx8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/exx8/subscriptions","organizations_url":"https://api.github.com/users/exx8/orgs","repos_url":"https://api.github.com/users/exx8/repos","events_url":"https://api.github.com/users/exx8/events{/privacy}","received_events_url":"https://api.github.com/users/exx8/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2022-03-27T13:02:41Z","updated_at":"2022-03-28T06:04:13Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"# Prerequisites\r\n\r\nPlease answer the following questions for yourself before submitting an issue.\r\n\r\n- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.\r\n- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)\r\n- [X]I checked to make sure that this issue has not been filed already.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/blob/master/official/projects/vit/modeling/vit.py\r\n## 2. Describe the bug\r\n\r\nOnce loading vit I get the following error:\r\n```\r\nWARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \r\nLayer Encoder has arguments ['self', 'num_layers', 'mlp_dim', 'num_heads', 'dropout_rate', 'attention_dropout_rate', 'kernel_regularizer', 'inputs_positions', 'init_stochastic_depth_rate', 'kernel_initializer', 'add_pos_embed']\r\nin `__init__` and therefore must override `get_config()`.\r\n\r\nExample:\r\n\r\nclass CustomLayer(keras.layers.Layer):\r\n    def __init__(self, arg1, arg2):\r\n        super().__init__()\r\n        self.arg1 = arg1\r\n        self.arg2 = arg2\r\n\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config.update({\r\n            \"arg1\": self.arg1,\r\n            \"arg2\": self.arg2,\r\n        })\r\n        return config\r\nWARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \r\nLayer Encoder has arguments ['self', 'num_layers', 'mlp_dim', 'num_heads', 'dropout_rate', 'attention_dropout_rate', 'kernel_regularizer', 'inputs_positions', 'init_stochastic_depth_rate', 'kernel_initializer', 'add_pos_embed']\r\nin `__init__` and therefore must override `get_config()`.\r\n\r\nExample:\r\n\r\nclass CustomLayer(keras.layers.Layer):\r\n    def __init__(self, arg1, arg2):\r\n        super().__init__()\r\n        self.arg1 = arg1\r\n        self.arg2 = arg2\r\n\r\n    def get_config(self):\r\n        config = super().get_config()\r\n        config.update({\r\n            \"arg1\": self.arg1,\r\n            \"arg2\": self.arg2,\r\n        })\r\n        return config\r\n2022-03-27 15:48:13.914733: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\r\n```\r\nOnce I try to save the model\r\n`model.save(\"/sda/Eran/imagenet-in-np/1.2M-Transformer-test\")\r\n`\r\nI get:\r\n`2022-03-27 15:52:29.493875: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:absl:Found untraced functions such as posembed_input_layer_call_fn, posembed_input_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 975). These functions will not be directly callable after loading.\r\n`\r\n## 3. Steps to reproduce\r\n\r\nimport vit.\r\nget the 1st error.\r\ntrain the model.\r\ntry to save the model,\r\nget the 2nd error.\r\n\r\nI've noticed that some of the weight remains unchanged. Maybe it is related to the errors?\r\n## 4. Expected behavior\r\n\r\nThe model should be loaded succesfully; all the wights should have some flexibility during training\r\n## 5. Additional context\r\n\r\nInclude any logs that would be helpful to diagnose the problem.\r\n\r\n## 6. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux 20.04\r\n- Mobile device name if the issue happens on a mobile device:X\r\n- TensorFlow installed from (source or binary): tensorflow 2.8\r\n- TensorFlow version (use command below):\r\n- Python version: 3.8.10\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\nSun Mar 27 16:01:41 2022       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  NVIDIA GeForce ...  On   | 00000000:17:00.0 Off |                  N/A |\r\n| 27%   31C    P8    17W / 250W |      5MiB / 11264MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  NVIDIA GeForce ...  On   | 00000000:65:00.0 Off |                  N/A |\r\n| 27%   31C    P8     1W / 250W |     68MiB / 11264MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n<!-- \r\nCollect system information using our environment capture script.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can also obtain the TensorFlow version with:\r\n\r\n1. TensorFlow 1.0\r\n`python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n\r\n2. TensorFlow 2.0\r\n`python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n-->\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10562/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10562/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10561","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10561/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10561/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10561/events","html_url":"https://github.com/tensorflow/models/issues/10561","id":1182397604,"node_id":"I_kwDOAwv_Dc5GefSk","number":10561,"title":"No bounding box on my Test image","user":{"login":"Annieliaquat","id":43025113,"node_id":"MDQ6VXNlcjQzMDI1MTEz","avatar_url":"https://avatars.githubusercontent.com/u/43025113?v=4","gravatar_id":"","url":"https://api.github.com/users/Annieliaquat","html_url":"https://github.com/Annieliaquat","followers_url":"https://api.github.com/users/Annieliaquat/followers","following_url":"https://api.github.com/users/Annieliaquat/following{/other_user}","gists_url":"https://api.github.com/users/Annieliaquat/gists{/gist_id}","starred_url":"https://api.github.com/users/Annieliaquat/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Annieliaquat/subscriptions","organizations_url":"https://api.github.com/users/Annieliaquat/orgs","repos_url":"https://api.github.com/users/Annieliaquat/repos","events_url":"https://api.github.com/users/Annieliaquat/events{/privacy}","received_events_url":"https://api.github.com/users/Annieliaquat/received_events","type":"User","site_admin":false},"labels":[{"id":473246400,"node_id":"MDU6TGFiZWw0NzMyNDY0MDA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:feature","name":"type:feature","color":"50bcc4","default":false,"description":""},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false},"assignees":[{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2022-03-27T07:02:58Z","updated_at":"2022-03-29T07:31:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, I have been using a remote ubuntu system for my object detection training and testing. Everything went well and my test image was also shown with a bounding box and label. \r\nBut the system had some issue and I couldn't perform my task further on that system, but now I have started my work in colab.\r\nEverything here also goes well but the only thing which is making issue is that, when I test my image no bounding box is drawn around my image. I have tried every possible solution but its not working. \r\nI don't know if there is any special setting for colab. \r\nHere is the final code I used for testing my image. In this code when I changed the parameter \"max_box_to_draw\" from 30 to 100, bounding box was drawn automatically. I have done same thing in colab but its not working.. \r\nPlease if anyone has gone throw this problem before and has find a solution then plz help me..\r\n\r\nimg = cv2.imread(IMAGE_PATH)\r\nimage_np = np.array(img)\r\n\r\ninput_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\r\ndetections = detect_fn(input_tensor)\r\n\r\nnum_detections = int(detections.pop('num_detections'))\r\ndetections = {key: value[0, :num_detections].numpy()\r\n              for key, value in detections.items()}\r\ndetections['num_detections'] = num_detections\r\n\r\n# detection_classes should be ints.\r\ndetections['detection_classes'] = detections['detection_classes'].astype(np.int64)\r\n\r\nlabel_id_offset = 1\r\nimage_np_with_detections = image_np.copy()\r\n\r\nviz_utils.visualize_boxes_and_labels_on_image_array(\r\n            image_np_with_detections,\r\n            detections['detection_boxes'],\r\n            detections['detection_classes']+label_id_offset,\r\n            detections['detection_scores'],\r\n            category_index,\r\n            use_normalized_coordinates=True,\r\n            line_thickness=9,\r\n            #instance_masks=detections.get('detection_masks'),\r\n            max_boxes_to_draw=100,\r\n            min_score_thresh=.30,\r\n            agnostic_mode=True            )\r\n\r\ncv2.resize(image_np_with_detections,(500, 500),interpolation = cv2.INTER_NEAREST)\r\nplt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\r\nplt.show()\r\n\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10561/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10561/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10559","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10559/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10559/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10559/events","html_url":"https://github.com/tensorflow/models/issues/10559","id":1180802932,"node_id":"I_kwDOAwv_Dc5GYZ90","number":10559,"title":"Documentation needed for video_ssl (for the paper Spatiotemporal Contrastive Video Representation Learning)","user":{"login":"alpargun","id":52760747,"node_id":"MDQ6VXNlcjUyNzYwNzQ3","avatar_url":"https://avatars.githubusercontent.com/u/52760747?v=4","gravatar_id":"","url":"https://api.github.com/users/alpargun","html_url":"https://github.com/alpargun","followers_url":"https://api.github.com/users/alpargun/followers","following_url":"https://api.github.com/users/alpargun/following{/other_user}","gists_url":"https://api.github.com/users/alpargun/gists{/gist_id}","starred_url":"https://api.github.com/users/alpargun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/alpargun/subscriptions","organizations_url":"https://api.github.com/users/alpargun/orgs","repos_url":"https://api.github.com/users/alpargun/repos","events_url":"https://api.github.com/users/alpargun/events{/privacy}","received_events_url":"https://api.github.com/users/alpargun/received_events","type":"User","site_admin":false},"labels":[{"id":519009460,"node_id":"MDU6TGFiZWw1MTkwMDk0NjA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:docs","name":"type:docs","color":"e8c25c","default":false,"description":""},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-25T13:34:35Z","updated_at":"2022-03-28T14:02:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Documentation is needed for running the code for video_ssl (for the paper _\"Spatiotemporal Contrastive Video Representation Learning\".\r\nHere is the link for the documentation: https://github.com/tensorflow/models/tree/master/official/projects/video_ssl\r\n\r\nI would also be very grateful if any of you were able to run the code and share some tips. Thanks.","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10559/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10559/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10558","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10558/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10558/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10558/events","html_url":"https://github.com/tensorflow/models/issues/10558","id":1180736853,"node_id":"I_kwDOAwv_Dc5GYJ1V","number":10558,"title":"Eager Few Shot Object Detection Colab Example code is not working ","user":{"login":"kotran88","id":20656932,"node_id":"MDQ6VXNlcjIwNjU2OTMy","avatar_url":"https://avatars.githubusercontent.com/u/20656932?v=4","gravatar_id":"","url":"https://api.github.com/users/kotran88","html_url":"https://github.com/kotran88","followers_url":"https://api.github.com/users/kotran88/followers","following_url":"https://api.github.com/users/kotran88/following{/other_user}","gists_url":"https://api.github.com/users/kotran88/gists{/gist_id}","starred_url":"https://api.github.com/users/kotran88/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kotran88/subscriptions","organizations_url":"https://api.github.com/users/kotran88/orgs","repos_url":"https://api.github.com/users/kotran88/repos","events_url":"https://api.github.com/users/kotran88/events{/privacy}","received_events_url":"https://api.github.com/users/kotran88/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false},"assignees":[{"login":"yeqingli","id":13264584,"node_id":"MDQ6VXNlcjEzMjY0NTg0","avatar_url":"https://avatars.githubusercontent.com/u/13264584?v=4","gravatar_id":"","url":"https://api.github.com/users/yeqingli","html_url":"https://github.com/yeqingli","followers_url":"https://api.github.com/users/yeqingli/followers","following_url":"https://api.github.com/users/yeqingli/following{/other_user}","gists_url":"https://api.github.com/users/yeqingli/gists{/gist_id}","starred_url":"https://api.github.com/users/yeqingli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/yeqingli/subscriptions","organizations_url":"https://api.github.com/users/yeqingli/orgs","repos_url":"https://api.github.com/users/yeqingli/repos","events_url":"https://api.github.com/users/yeqingli/events{/privacy}","received_events_url":"https://api.github.com/users/yeqingli/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-25T12:27:32Z","updated_at":"2022-03-28T17:34:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I thought a year ago, it was working right. \r\nbut I just run all the sample code Eager Few Shot Object Detection Colab now, \r\n\r\nit cause error in \r\nCreate model and restore weights for all but last layer\r\n\r\nHow can I deal with it? \r\n\r\n```\r\nBuilding model and restoring weights for fine-tuning...\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\n[<ipython-input-19-5906ad4ff27f>](https://localhost:8080/#) in <module>()\r\n     37 # Run model through a dummy image so that variables are created\r\n     38 image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\r\n---> 39 prediction_dict = detection_model.predict(image, shapes)\r\n     40 _ = detection_model.postprocess(prediction_dict, shapes)\r\n     41 print('Weights restored!')\r\n\r\n3 frames\r\n[/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py](https://localhost:8080/#) in _extract_features(self, preprocessed_inputs)\r\n    223 \r\n    224     image_features = self.classification_backbone(\r\n--> 225         ops.pad_to_multiple(preprocessed_inputs, self._pad_to_multiple))\r\n    226 \r\n    227     feature_block_list = []\r\n\r\nUnimplementedError: Exception encountered when calling layer \"conv1_conv\" (type Conv2D).\r\n\r\nDNN library is not found. [Op:Conv2D]\r\n\r\nCall arguments received:\r\n  • inputs=tf.Tensor(shape=(1, 646, 646, 3), dtype=float32)\r\n```","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10558/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10558/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10557","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10557/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10557/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10557/events","html_url":"https://github.com/tensorflow/models/issues/10557","id":1180251359,"node_id":"I_kwDOAwv_Dc5GWTTf","number":10557,"title":"What is different between task.build_model() and factory.build_*_model ?","user":{"login":"DoHoNi","id":13118617,"node_id":"MDQ6VXNlcjEzMTE4NjE3","avatar_url":"https://avatars.githubusercontent.com/u/13118617?v=4","gravatar_id":"","url":"https://api.github.com/users/DoHoNi","html_url":"https://github.com/DoHoNi","followers_url":"https://api.github.com/users/DoHoNi/followers","following_url":"https://api.github.com/users/DoHoNi/following{/other_user}","gists_url":"https://api.github.com/users/DoHoNi/gists{/gist_id}","starred_url":"https://api.github.com/users/DoHoNi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/DoHoNi/subscriptions","organizations_url":"https://api.github.com/users/DoHoNi/orgs","repos_url":"https://api.github.com/users/DoHoNi/repos","events_url":"https://api.github.com/users/DoHoNi/events{/privacy}","received_events_url":"https://api.github.com/users/DoHoNi/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-25T01:53:38Z","updated_at":"2022-03-25T05:30:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"<!--\r\nAs per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.\r\n\r\nWe will automatically close questions and help related issues.\r\n\r\nPlease go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for questions and help.\r\n\r\n-->\r\n\r\nI am training my model using codes in models/official/vision/beta.\r\nI am curious about the difference between taking the **registered task** and **using the factory** to return a specific model.\r\nI recognized that a way getting a model is calling registered tasks and calling build_model() when I start to train my model.\r\nIn the following way,\r\nhttps://github.com/tensorflow/models/blob/871c4e0a393ef4385534bee55354a5df8aa1ccf4/official/vision/beta/train.py#L56\r\nhttps://github.com/tensorflow/models/blob/871c4e0a393ef4385534bee55354a5df8aa1ccf4/official/core/train_utils.py#L221\r\n\r\nHowever, I found out the way is different when I export my model.\r\nI used the code ( https://github.com/tensorflow/models/blob/master/official/vision/beta/serving/export_saved_model.py) to export my model.\r\nIn this case, they use 'factory' defined models/official/vision/beta/modeling/factory (https://github.com/tensorflow/models/blob/master/official/vision/beta/modeling/factory.py) to get a model.  \r\nhttps://github.com/tensorflow/models/blob/c1c9bb0fb019de246ea268b1f15e0c76a76138f1/official/vision/beta/serving/image_classification.py#L31-L38\r\n\r\nSo I was very confused, and I wonder why you make and use 'factory' in models/official/vision/beta/modeling instead of calling a model using a task.","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10557/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10557/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10555","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10555/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10555/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10555/events","html_url":"https://github.com/tensorflow/models/issues/10555","id":1179452551,"node_id":"I_kwDOAwv_Dc5GTQSH","number":10555,"title":"EfficientDet models - No detections after training on custom dataset","user":{"login":"IvanGarcia7","id":37554728,"node_id":"MDQ6VXNlcjM3NTU0NzI4","avatar_url":"https://avatars.githubusercontent.com/u/37554728?v=4","gravatar_id":"","url":"https://api.github.com/users/IvanGarcia7","html_url":"https://github.com/IvanGarcia7","followers_url":"https://api.github.com/users/IvanGarcia7/followers","following_url":"https://api.github.com/users/IvanGarcia7/following{/other_user}","gists_url":"https://api.github.com/users/IvanGarcia7/gists{/gist_id}","starred_url":"https://api.github.com/users/IvanGarcia7/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/IvanGarcia7/subscriptions","organizations_url":"https://api.github.com/users/IvanGarcia7/orgs","repos_url":"https://api.github.com/users/IvanGarcia7/repos","events_url":"https://api.github.com/users/IvanGarcia7/events{/privacy}","received_events_url":"https://api.github.com/users/IvanGarcia7/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-24T12:32:00Z","updated_at":"2022-03-24T17:46:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Prerequisites\r\n\r\n- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.\r\n- [X] I am reporting the issue to the correct repository. (Model Garden official or research directory)\r\n- [x] I checked to make sure that this issue has not already been filed.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config\r\n\r\n## 2. Describe the bug\r\n\r\nI am trying to re-train EfficientDet D4, coming from Tensorflow Model Zoo (http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz) on my dataset.\r\n\r\nThe configuration file I am using is the following:\r\n\r\n```\r\nmodel {\r\n  ssd {\r\n    inplace_batchnorm_update: true\r\n    freeze_batchnorm: false\r\n    num_classes: 8\r\n    add_background_class: false\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n        use_matmul_gather: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    encode_background_as_zeros: true\r\n    anchor_generator {\r\n      multiscale_anchor_generator {\r\n        min_level: 3\r\n        max_level: 7\r\n        anchor_scale: 4.0\r\n        aspect_ratios: [1.0, 2.0, 0.5]\r\n        scales_per_octave: 3\r\n      }\r\n    }\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 1024\r\n        max_dimension: 1024\r\n        pad_to_max_dimension: true\r\n        }\r\n    }\r\n    box_predictor {\r\n      weight_shared_convolutional_box_predictor {\r\n        depth: 224\r\n        class_prediction_bias_init: -4.6\r\n        conv_hyperparams {\r\n          force_use_bias: true\r\n          activation: SWISH\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            random_normal_initializer {\r\n              stddev: 0.01\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            scale: true\r\n            decay: 0.99\r\n            epsilon: 0.001\r\n          }\r\n        }\r\n        num_layers_before_predictor: 4\r\n        kernel_size: 3\r\n        use_depthwise: true\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_efficientnet-b4_bifpn_keras'\r\n      bifpn {\r\n        min_level: 3\r\n        max_level: 7\r\n        num_iterations: 7\r\n        num_filters: 224\r\n      }\r\n      conv_hyperparams {\r\n        force_use_bias: true\r\n        activation: SWISH\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          scale: true,\r\n          decay: 0.99,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid_focal {\r\n          alpha: 0.25\r\n          gamma: 1.5\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    normalize_loc_loss_by_codesize: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.5\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  fine_tune_checkpoint: \"/home/models/efd4/checkpoint/ckpt-0\"\r\n  fine_tune_checkpoint_version: V2\r\n  fine_tune_checkpoint_type: \"detection\"\r\n  batch_size: 1\r\n  sync_replicas: true\r\n  startup_delay_steps: 0\r\n  replicas_to_aggregate: 8\r\n  use_bfloat16: true\r\n  num_steps: 2000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    random_scale_crop_and_pad_to_square {\r\n      output_size: 1024\r\n      scale_min: 0.1\r\n      scale_max: 2.0\r\n    }\r\n  }\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        cosine_decay_learning_rate {\r\n          learning_rate_base: 0.002\r\n          total_steps: 2000\r\n          warmup_learning_rate: .0001\r\n          warmup_steps: 500\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  max_number_of_boxes: 100\r\n  unpad_groundtruth_tensors: false\r\n}\r\n\r\ntrain_input_reader: {\r\n  label_map_path: \"/home/labels/label_map.txt\"\r\n  tf_record_input_reader {\r\n    input_path: \"/home/records/train.tfrecord\"\r\n  }\r\n}\r\n\r\neval_config: {\r\n  metrics_set: \"coco_detection_metrics\"\r\n  use_moving_averages: false\r\n  batch_size: 1;\r\n}\r\n\r\neval_input_reader: {\r\n  label_map_path: \"/home/labels/label_map.txt\"\r\n  shuffle: false\r\n  num_epochs: 1\r\n  tf_record_input_reader {\r\n    input_path: \"/home/records/validation.tfrecord\"\r\n  }\r\n}\r\n```\r\n\r\nWhen I make use of model_main_tf2 to start training, no error appears. However, when I check the model accuracy, it does not detect anything. \r\n\r\n```\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\r\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\r\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\r\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\r\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\r\n```\r\n\r\n\r\nI try to modify parameters like learning rate, the number of epochs, etc but doesn't work\r\n\r\n## 3. Steps to reproduce\r\n\r\nTo Fine-Tuning this model, I have followed the steps established in the following guide (https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html). \r\n\r\n```\r\npython /home/drive/MyDrive/VISDRONE/model_main_tf2.py \\\r\n    --pipeline_config_path={pipeline_file} \\\r\n    --model_dir={model_dir} \\\r\n    --alsologtostderr \\\r\n    --num_train_steps={num_steps} \\\r\n    --sample_1_of_n_eval_examples=1 \\\r\n    --num_eval_steps={num_eval_steps}\r\n```\r\n\r\n```\r\n2022-03-24 14:56:39.530945: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI0324 14:56:39.539781 140467518502784 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nINFO:tensorflow:Maybe overwriting train_steps: 2000\r\nI0324 14:56:39.543960 140467518502784 config_util.py:552] Maybe overwriting train_steps: 2000\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI0324 14:56:39.544119 140467518502784 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nI0324 14:56:39.553249 140467518502784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\r\nI0324 14:56:39.553378 140467518502784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\r\nI0324 14:56:39.553517 140467518502784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\r\nI0324 14:56:39.558310 140467518502784 efficientnet_model.py:144] round_filter input=32 output=48\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.580137 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.582051 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.584519 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.585638 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.592988 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.597373 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.603657 140467518502784 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0324 14:56:39.603788 140467518502784 efficientnet_model.py:144] round_filter input=16 output=24\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.619617 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.620819 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.623020 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.624058 140467518502784 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nI0324 14:56:39.829434 140467518502784 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0324 14:56:39.829590 140467518502784 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0324 14:56:40.442389 140467518502784 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0324 14:56:40.442584 140467518502784 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0324 14:56:41.058132 140467518502784 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0324 14:56:41.058324 140467518502784 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0324 14:56:41.971299 140467518502784 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0324 14:56:41.971578 140467518502784 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0324 14:56:42.896141 140467518502784 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0324 14:56:42.896331 140467518502784 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0324 14:56:44.146403 140467518502784 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0324 14:56:44.146590 140467518502784 efficientnet_model.py:144] round_filter input=320 output=448\r\nI0324 14:56:44.446191 140467518502784 efficientnet_model.py:144] round_filter input=1280 output=1792\r\nI0324 14:56:44.504505 140467518502784 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nW0324 14:56:44.738715 140467518502784 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nINFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/VISDRONE/train.record']\r\nI0324 14:56:44.751177 140467518502784 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/VISDRONE/train.record']\r\nINFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/VISDRONE/train.record']\r\nI0324 14:56:44.751728 140467518502784 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/VISDRONE/train.record']\r\nINFO:tensorflow:Number of filenames to read: 1\r\nI0324 14:56:44.751873 140467518502784 dataset_builder.py:81] Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW0324 14:56:44.752046 140467518502784 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\r\nW0324 14:56:44.754448 140467518502784 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW0324 14:56:44.776529 140467518502784 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nW0324 14:56:49.483746 140467518502784 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0324 14:56:52.317593 140467518502784 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\n/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse fn_output_signature instead\r\nW0324 14:57:59.473496 140462682519296 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse fn_output_signature instead\r\nWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nW0324 14:58:17.434093 140462682519296 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nW0324 14:58:42.918556 140462682519296 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nW0324 14:59:06.517044 140462682519296 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nWARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nW0324 14:59:31.055212 140462682519296 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\r\nINFO:tensorflow:Step 100 per-step time 4.057s\r\nI0324 15:04:44.796877 140467518502784 model_lib_v2.py:707] Step 100 per-step time 4.057s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.0777053,\r\n 'Loss/localization_loss': 0.71329135,\r\n 'Loss/regularization_loss': 0.048915524,\r\n 'Loss/total_loss': 1.8399122,\r\n 'learning_rate': 0.0002}\r\nI0324 15:04:44.797298 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.0777053,\r\n 'Loss/localization_loss': 0.71329135,\r\n 'Loss/regularization_loss': 0.048915524,\r\n 'Loss/total_loss': 1.8399122,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 200 per-step time 2.467s\r\nI0324 15:08:51.406273 140467518502784 model_lib_v2.py:707] Step 200 per-step time 2.467s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1751853,\r\n 'Loss/localization_loss': 0.7252056,\r\n 'Loss/regularization_loss': 0.04891498,\r\n 'Loss/total_loss': 1.949306,\r\n 'learning_rate': 0.0002}\r\nI0324 15:08:51.406655 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1751853,\r\n 'Loss/localization_loss': 0.7252056,\r\n 'Loss/regularization_loss': 0.04891498,\r\n 'Loss/total_loss': 1.949306,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 300 per-step time 2.476s\r\nI0324 15:12:58.999202 140467518502784 model_lib_v2.py:707] Step 300 per-step time 2.476s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1473204,\r\n 'Loss/localization_loss': 0.696468,\r\n 'Loss/regularization_loss': 0.048914447,\r\n 'Loss/total_loss': 1.8927028,\r\n 'learning_rate': 0.0002}\r\nI0324 15:12:58.999642 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1473204,\r\n 'Loss/localization_loss': 0.696468,\r\n 'Loss/regularization_loss': 0.048914447,\r\n 'Loss/total_loss': 1.8927028,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 400 per-step time 2.472s\r\nI0324 15:17:06.168886 140467518502784 model_lib_v2.py:707] Step 400 per-step time 2.472s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.3694557,\r\n 'Loss/localization_loss': 0.66213036,\r\n 'Loss/regularization_loss': 0.048913937,\r\n 'Loss/total_loss': 2.0805001,\r\n 'learning_rate': 0.0002}\r\nI0324 15:17:06.169253 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.3694557,\r\n 'Loss/localization_loss': 0.66213036,\r\n 'Loss/regularization_loss': 0.048913937,\r\n 'Loss/total_loss': 2.0805001,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 500 per-step time 2.470s\r\nI0324 15:21:13.213133 140467518502784 model_lib_v2.py:707] Step 500 per-step time 2.470s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1455597,\r\n 'Loss/localization_loss': 0.6874537,\r\n 'Loss/regularization_loss': 0.048913423,\r\n 'Loss/total_loss': 1.8819268,\r\n 'learning_rate': 0.0002}\r\nI0324 15:21:13.213557 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1455597,\r\n 'Loss/localization_loss': 0.6874537,\r\n 'Loss/regularization_loss': 0.048913423,\r\n 'Loss/total_loss': 1.8819268,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 600 per-step time 2.472s\r\nI0324 15:25:20.460671 140467518502784 model_lib_v2.py:707] Step 600 per-step time 2.472s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1520298,\r\n 'Loss/localization_loss': 0.7305322,\r\n 'Loss/regularization_loss': 0.04891293,\r\n 'Loss/total_loss': 1.9314749,\r\n 'learning_rate': 0.0002}\r\nI0324 15:25:20.461070 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1520298,\r\n 'Loss/localization_loss': 0.7305322,\r\n 'Loss/regularization_loss': 0.04891293,\r\n 'Loss/total_loss': 1.9314749,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 700 per-step time 2.472s\r\nI0324 15:29:27.649186 140467518502784 model_lib_v2.py:707] Step 700 per-step time 2.472s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1544534,\r\n 'Loss/localization_loss': 0.716094,\r\n 'Loss/regularization_loss': 0.048912443,\r\n 'Loss/total_loss': 1.9194598,\r\n 'learning_rate': 0.0002}\r\nI0324 15:29:27.649561 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1544534,\r\n 'Loss/localization_loss': 0.716094,\r\n 'Loss/regularization_loss': 0.048912443,\r\n 'Loss/total_loss': 1.9194598,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 800 per-step time 2.460s\r\nI0324 15:33:33.606482 140467518502784 model_lib_v2.py:707] Step 800 per-step time 2.460s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.144963,\r\n 'Loss/localization_loss': 0.68470913,\r\n 'Loss/regularization_loss': 0.048911978,\r\n 'Loss/total_loss': 1.8785841,\r\n 'learning_rate': 0.0002}\r\nI0324 15:33:33.606925 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.144963,\r\n 'Loss/localization_loss': 0.68470913,\r\n 'Loss/regularization_loss': 0.048911978,\r\n 'Loss/total_loss': 1.8785841,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 900 per-step time 2.463s\r\nI0324 15:37:39.929426 140467518502784 model_lib_v2.py:707] Step 900 per-step time 2.463s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.0874641,\r\n 'Loss/localization_loss': 0.70858914,\r\n 'Loss/regularization_loss': 0.048911538,\r\n 'Loss/total_loss': 1.8449647,\r\n 'learning_rate': 0.0002}\r\nI0324 15:37:39.929794 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.0874641,\r\n 'Loss/localization_loss': 0.70858914,\r\n 'Loss/regularization_loss': 0.048911538,\r\n 'Loss/total_loss': 1.8449647,\r\n 'learning_rate': 0.0002}\r\nINFO:tensorflow:Step 1000 per-step time 2.466s\r\nI0324 15:41:46.560392 140467518502784 model_lib_v2.py:707] Step 1000 per-step time 2.466s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1569183,\r\n 'Loss/localization_loss': 0.7344822,\r\n 'Loss/regularization_loss': 0.048911124,\r\n 'Loss/total_loss': 1.9403117,\r\n 'learning_rate': 2e-05}\r\nI0324 15:41:46.560784 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1569183,\r\n 'Loss/localization_loss': 0.7344822,\r\n 'Loss/regularization_loss': 0.048911124,\r\n 'Loss/total_loss': 1.9403117,\r\n 'learning_rate': 2e-05}\r\nINFO:tensorflow:Step 1100 per-step time 2.506s\r\nI0324 15:45:57.157139 140467518502784 model_lib_v2.py:707] Step 1100 per-step time 2.506s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.170136,\r\n 'Loss/localization_loss': 0.73082036,\r\n 'Loss/regularization_loss': 0.04891106,\r\n 'Loss/total_loss': 1.9498675,\r\n 'learning_rate': 2e-05}\r\nI0324 15:45:57.157560 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.170136,\r\n 'Loss/localization_loss': 0.73082036,\r\n 'Loss/regularization_loss': 0.04891106,\r\n 'Loss/total_loss': 1.9498675,\r\n 'learning_rate': 2e-05}\r\nINFO:tensorflow:Step 1200 per-step time 2.481s\r\nI0324 15:50:05.257278 140467518502784 model_lib_v2.py:707] Step 1200 per-step time 2.481s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1441879,\r\n 'Loss/localization_loss': 0.6731573,\r\n 'Loss/regularization_loss': 0.04891104,\r\n 'Loss/total_loss': 1.8662562,\r\n 'learning_rate': 2e-05}\r\nI0324 15:50:05.257679 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1441879,\r\n 'Loss/localization_loss': 0.6731573,\r\n 'Loss/regularization_loss': 0.04891104,\r\n 'Loss/total_loss': 1.8662562,\r\n 'learning_rate': 2e-05}\r\nINFO:tensorflow:Step 1300 per-step time 2.476s\r\nI0324 15:54:12.866213 140467518502784 model_lib_v2.py:707] Step 1300 per-step time 2.476s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.0104654,\r\n 'Loss/localization_loss': 0.72844565,\r\n 'Loss/regularization_loss': 0.048911005,\r\n 'Loss/total_loss': 1.787822,\r\n 'learning_rate': 2e-05}\r\nI0324 15:54:12.866582 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.0104654,\r\n 'Loss/localization_loss': 0.72844565,\r\n 'Loss/regularization_loss': 0.048911005,\r\n 'Loss/total_loss': 1.787822,\r\n 'learning_rate': 2e-05}\r\nINFO:tensorflow:Step 1400 per-step time 2.480s\r\nI0324 15:58:20.906429 140467518502784 model_lib_v2.py:707] Step 1400 per-step time 2.480s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1930686,\r\n 'Loss/localization_loss': 0.6976074,\r\n 'Loss/regularization_loss': 0.048910983,\r\n 'Loss/total_loss': 1.939587,\r\n 'learning_rate': 2e-05}\r\nI0324 15:58:20.906798 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1930686,\r\n 'Loss/localization_loss': 0.6976074,\r\n 'Loss/regularization_loss': 0.048910983,\r\n 'Loss/total_loss': 1.939587,\r\n 'learning_rate': 2e-05}\r\nINFO:tensorflow:Step 1500 per-step time 2.472s\r\nI0324 16:02:28.107308 140467518502784 model_lib_v2.py:707] Step 1500 per-step time 2.472s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1081508,\r\n 'Loss/localization_loss': 0.663561,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 1.8206228,\r\n 'learning_rate': 2e-06}\r\nI0324 16:02:28.107687 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1081508,\r\n 'Loss/localization_loss': 0.663561,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 1.8206228,\r\n 'learning_rate': 2e-06}\r\nINFO:tensorflow:Step 1600 per-step time 2.473s\r\nI0324 16:06:35.467271 140467518502784 model_lib_v2.py:707] Step 1600 per-step time 2.473s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.2835001,\r\n 'Loss/localization_loss': 0.915443,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 2.247854,\r\n 'learning_rate': 2e-06}\r\nI0324 16:06:35.467811 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.2835001,\r\n 'Loss/localization_loss': 0.915443,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 2.247854,\r\n 'learning_rate': 2e-06}\r\nINFO:tensorflow:Step 1700 per-step time 2.477s\r\nI0324 16:10:43.180331 140467518502784 model_lib_v2.py:707] Step 1700 per-step time 2.477s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.146557,\r\n 'Loss/localization_loss': 0.66494846,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 1.8604164,\r\n 'learning_rate': 2e-06}\r\nI0324 16:10:43.180699 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.146557,\r\n 'Loss/localization_loss': 0.66494846,\r\n 'Loss/regularization_loss': 0.048910964,\r\n 'Loss/total_loss': 1.8604164,\r\n 'learning_rate': 2e-06}\r\nINFO:tensorflow:Step 1800 per-step time 2.473s\r\nI0324 16:14:50.469713 140467518502784 model_lib_v2.py:707] Step 1800 per-step time 2.473s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1496946,\r\n 'Loss/localization_loss': 0.6987976,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.8974031,\r\n 'learning_rate': 2e-06}\r\nI0324 16:14:50.470112 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1496946,\r\n 'Loss/localization_loss': 0.6987976,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.8974031,\r\n 'learning_rate': 2e-06}\r\nINFO:tensorflow:Step 1900 per-step time 2.469s\r\nI0324 16:18:57.363423 140467518502784 model_lib_v2.py:707] Step 1900 per-step time 2.469s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.2016695,\r\n 'Loss/localization_loss': 0.74829096,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.9988713,\r\n 'learning_rate': 2e-06}\r\nI0324 16:18:57.363805 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.2016695,\r\n 'Loss/localization_loss': 0.74829096,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.9988713,\r\n 'learning_rate': 2e-06}\r\nINFO:tensorflow:Step 2000 per-step time 2.463s\r\nI0324 16:23:03.656679 140467518502784 model_lib_v2.py:707] Step 2000 per-step time 2.463s\r\nINFO:tensorflow:{'Loss/classification_loss': 1.1624724,\r\n 'Loss/localization_loss': 0.64188105,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.8532643,\r\n 'learning_rate': 2e-06}\r\nI0324 16:23:03.657085 140467518502784 model_lib_v2.py:708] {'Loss/classification_loss': 1.1624724,\r\n 'Loss/localization_loss': 0.64188105,\r\n 'Loss/regularization_loss': 0.04891097,\r\n 'Loss/total_loss': 1.8532643,\r\n 'learning_rate': 2e-06}\r\n```\r\n\r\n\r\n```\r\nimport re\r\nimport numpy as np\r\n\r\noutput_directory = '/home/fine_tuned_model'\r\n\r\n#place the model weights you would like to export here\r\nlast_model_path = '/home/training/'\r\nprint(last_model_path)\r\n!python /content/models/research/object_detection/exporter_main_v2.py \\\r\n    --trained_checkpoint_dir {last_model_path} \\\r\n    --output_directory {output_directory} \\\r\n    --pipeline_config_path {pipeline_file}\r\n```\r\n\r\n\r\n```\r\n2022-03-24 16:24:11.513483: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nI0324 16:24:11.523551 140297703389056 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\r\nI0324 16:24:11.523777 140297703389056 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\r\nI0324 16:24:11.523884 140297703389056 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\r\nI0324 16:24:11.528325 140297703389056 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0324 16:24:11.561406 140297703389056 efficientnet_model.py:144] round_filter input=32 output=48\r\nI0324 16:24:11.561547 140297703389056 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0324 16:24:11.716008 140297703389056 efficientnet_model.py:144] round_filter input=16 output=24\r\nI0324 16:24:11.716274 140297703389056 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0324 16:24:12.094801 140297703389056 efficientnet_model.py:144] round_filter input=24 output=32\r\nI0324 16:24:12.095036 140297703389056 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0324 16:24:12.588015 140297703389056 efficientnet_model.py:144] round_filter input=40 output=56\r\nI0324 16:24:12.588222 140297703389056 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0324 16:24:13.161465 140297703389056 efficientnet_model.py:144] round_filter input=80 output=112\r\nI0324 16:24:13.161654 140297703389056 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0324 16:24:13.751483 140297703389056 efficientnet_model.py:144] round_filter input=112 output=160\r\nI0324 16:24:13.751679 140297703389056 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0324 16:24:14.531807 140297703389056 efficientnet_model.py:144] round_filter input=192 output=272\r\nI0324 16:24:14.532021 140297703389056 efficientnet_model.py:144] round_filter input=320 output=448\r\nI0324 16:24:14.732889 140297703389056 efficientnet_model.py:144] round_filter input=1280 output=1792\r\nI0324 16:24:14.775294 140297703389056 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nback_prop=False is deprecated. Consider using tf.stop_gradient instead.\r\nInstead of:\r\nresults = tf.map_fn(fn, elems, back_prop=False)\r\nUse:\r\nresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\r\nW0324 16:24:23.994653 140297703389056 deprecation.py:615] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nback_prop=False is deprecated. Consider using tf.stop_gradient instead.\r\nInstead of:\r\nresults = tf.map_fn(fn, elems, back_prop=False)\r\nUse:\r\nresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\r\n2022-03-24 16:24:54.173274: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f9891552510>, because it is not built.\r\nW0324 16:25:03.157266 140297703389056 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f9891552510>, because it is not built.\r\nW0324 16:26:53.641512 140297703389056 save.py:265] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 582). These functions will not be directly callable after loading.\r\nINFO:tensorflow:Assets written to: /home/fine_tuned_model/saved_model/assets\r\nI0324 16:28:18.870657 140297703389056 builder_impl.py:780] Assets written to: /home/fine_tuned_model/saved_model/assets\r\nINFO:tensorflow:Writing pipeline config file to /home/fine_tuned_model/pipeline.config\r\nI0324 16:28:22.083487 140297703389056 config_util.py:254] Writing pipeline config file to /home/fine_tuned_model/pipeline.config\r\n```\r\n\r\nTensorboard:\r\n\r\n<img width=\"692\" alt=\"1\" src=\"https://user-images.githubusercontent.com/37554728/159967066-ee717072-069d-4e9c-9789-69c0017c654d.png\">\r\n\r\n<img width=\"290\" alt=\"2\" src=\"https://user-images.githubusercontent.com/37554728/159967061-c52c3fab-6eed-4cd1-aa18-0aacfb05514f.png\">\r\n\r\nWhen I infer over one image, this is the detections['detection_boxes'] output:\r\n\r\n`tf.Tensor(\r\n[[[0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]\r\n  [0. 0. 0. 0.]]], shape=(1, 100, 4), dtype=float32)`\r\n\r\n## 4. Expected behavior\r\n\r\nSince I am re-training on existing classes in the pre-trained model, the MAP should not drop to 0, since both the learning rate and the number of steps are low. This error occurs with other models of the EfficientDet family. On the other hand, I have tested with another data set and the results are similar.\r\n\r\nFollowing the same process but re-training other models such as CenterNet this problem does not appear.\r\n\r\n## 5. System information\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 21.04\r\nTensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0\r\nPython version: 3.10.2\r\nCUDA/cuDNN version: 11.6/8.3\r\nGPU model and memory: Nvidia RTX 3080Ti 12GB","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10555/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10555/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10554","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10554/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10554/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10554/events","html_url":"https://github.com/tensorflow/models/issues/10554","id":1179245496,"node_id":"I_kwDOAwv_Dc5GSdu4","number":10554,"title":"hi can u help me","user":{"login":"rezah1369","id":100523440,"node_id":"U_kgDOBf3dsA","avatar_url":"https://avatars.githubusercontent.com/u/100523440?v=4","gravatar_id":"","url":"https://api.github.com/users/rezah1369","html_url":"https://github.com/rezah1369","followers_url":"https://api.github.com/users/rezah1369/followers","following_url":"https://api.github.com/users/rezah1369/following{/other_user}","gists_url":"https://api.github.com/users/rezah1369/gists{/gist_id}","starred_url":"https://api.github.com/users/rezah1369/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rezah1369/subscriptions","organizations_url":"https://api.github.com/users/rezah1369/orgs","repos_url":"https://api.github.com/users/rezah1369/repos","events_url":"https://api.github.com/users/rezah1369/events{/privacy}","received_events_url":"https://api.github.com/users/rezah1369/received_events","type":"User","site_admin":false},"labels":[{"id":387356495,"node_id":"MDU6TGFiZWwzODczNTY0OTU=","url":"https://api.github.com/repos/tensorflow/models/labels/stat:awaiting%20response","name":"stat:awaiting response","color":"f4b400","default":false,"description":"Waiting on input from the contributor"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-03-24T09:33:57Z","updated_at":"2022-03-26T04:10:31Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"i have problem about TF:\r\ni run:\r\n!rm -rf /content/output\r\n!python -m object_detection.model_main\r\npipeline_config_path= '/content/data/pipeline.config'\r\nmodel_dir= '/content/checkpoint/model.ckpt.data-00000-of-00001'\r\nnum_train_steps=5000\r\nnum_eval_steps=100\r\n\r\nmy error:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/content/models/research/object_detection/model_main.py\", line 108, in <module>\r\n    tf.app.run()\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/content/models/research/object_detection/model_main.py\", line 70, in main\r\n    FLAGS.sample_1_of_n_eval_on_train_examples))\r\n  File \"/content/models/research/object_detection/model_lib.py\", line 789, in create_estimator_and_inputs\r\n    pipeline_config_path, config_override=config_override)\r\n  File \"/content/models/research/object_detection/utils/config_util.py\", line 138, in get_configs_from_pipeline_file\r\n    proto_str = f.read()\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\r\n    self._preread_check()\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512)\r\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/compat.py\", line 71, in as_bytes\r\n    (bytes_or_text,))\r\nTypeError: Expected binary or unicode string, got None","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10554/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10554/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10553","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10553/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10553/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10553/events","html_url":"https://github.com/tensorflow/models/issues/10553","id":1178839660,"node_id":"I_kwDOAwv_Dc5GQ6ps","number":10553,"title":"what is the use of use_static_shapes ?","user":{"login":"dsnsabari","id":46018083,"node_id":"MDQ6VXNlcjQ2MDE4MDgz","avatar_url":"https://avatars.githubusercontent.com/u/46018083?v=4","gravatar_id":"","url":"https://api.github.com/users/dsnsabari","html_url":"https://github.com/dsnsabari","followers_url":"https://api.github.com/users/dsnsabari/followers","following_url":"https://api.github.com/users/dsnsabari/following{/other_user}","gists_url":"https://api.github.com/users/dsnsabari/gists{/gist_id}","starred_url":"https://api.github.com/users/dsnsabari/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/dsnsabari/subscriptions","organizations_url":"https://api.github.com/users/dsnsabari/orgs","repos_url":"https://api.github.com/users/dsnsabari/repos","events_url":"https://api.github.com/users/dsnsabari/events{/privacy}","received_events_url":"https://api.github.com/users/dsnsabari/received_events","type":"User","site_admin":false},"labels":[{"id":519009460,"node_id":"MDU6TGFiZWw1MTkwMDk0NjA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:docs","name":"type:docs","color":"e8c25c","default":false,"description":""},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-24T01:41:53Z","updated_at":"2022-03-24T01:41:53Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"when I compared the SSD mobilenet v2 config file with SSD mobilenet v3. use_static_shapes was set True in v3 and False in V2","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10553/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10553/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10552","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10552/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10552/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10552/events","html_url":"https://github.com/tensorflow/models/issues/10552","id":1177816824,"node_id":"I_kwDOAwv_Dc5GNA74","number":10552,"title":"Unable to get batched input argument from exported Object Detection Saved Model for TensorFlow Batch Serving","user":{"login":"ayusheebrane","id":102212352,"node_id":"U_kgDOBhejAA","avatar_url":"https://avatars.githubusercontent.com/u/102212352?v=4","gravatar_id":"","url":"https://api.github.com/users/ayusheebrane","html_url":"https://github.com/ayusheebrane","followers_url":"https://api.github.com/users/ayusheebrane/followers","following_url":"https://api.github.com/users/ayusheebrane/following{/other_user}","gists_url":"https://api.github.com/users/ayusheebrane/gists{/gist_id}","starred_url":"https://api.github.com/users/ayusheebrane/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ayusheebrane/subscriptions","organizations_url":"https://api.github.com/users/ayusheebrane/orgs","repos_url":"https://api.github.com/users/ayusheebrane/repos","events_url":"https://api.github.com/users/ayusheebrane/events{/privacy}","received_events_url":"https://api.github.com/users/ayusheebrane/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-23T09:02:41Z","updated_at":"2022-03-23T11:17:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_lib_v2.py\r\n\r\nI am using TensorFlow-2 Object Detection API to build my custom object detection model using FasterRCNN Resnet-152 640x640 Pretrained Model from the tf2 Model Zoo.  I have successfully trained my model and the checkpoints created are in below format - \r\n![image](https://user-images.githubusercontent.com/102212352/159668520-1f366287-a46d-42e6-af72-b48ff9630bf5.png)\r\nI then used [exporter_main_v2.py] (https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py) to export the model. I used --input_type as 'image_tensor' the first time and 'float_image_tensor' the second time.  After running the script saved_model.pb was generated and, the output folder looked like this - \r\n![image](https://user-images.githubusercontent.com/102212352/159670596-80c1a699-0714-4b96-a320-d673c197d941.png)\r\n![image](https://user-images.githubusercontent.com/102212352/159670741-a132c7f4-b298-4dcd-a255-d65fd8a8806a.png)\r\n \r\nTo get the meta data information, I ran the **saved_model_cli** command and this is how it looks -\r\n![image](https://user-images.githubusercontent.com/102212352/159677319-fdd27ca3-9bef-43d2-9dd2-0851c83ed4e8.png)\r\n\r\nI used the same saved_model.pb for **inferencing** using TF Serving command -\r\ntensorflow_model_server --port=8500 --model_name=detection_model --model_base_path=path_to_saved_model(/tfserve_savedmodel/)\r\nI was able to get the results for single image but cannot perform batch inferencing. \r\n\r\n**Points to consider**-\r\n1. I am using GRPC client to establish the connection to the server and I updated the code for batch inferencing. I was passing a  batch of numpy array of size (1,640,640,3) for single image and tried creating a np array (10,640,640,3) for a batch of 10 images and passing it to the server.\r\n2. I thought the input shape from the **SavedModel SignatureDef had shape: (1, -1, -1, 3)** and this is the reason I wasn't able to do for multiple images. Thus I updated the code in file [exporter_lib_v2.py](https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_lib_v2.py) and set the shape to shape=[None, None, None, 3] and exported the model. But even then I got the input shape as (1, -1, -1, 3). \r\n3. To dig deeper I checked the metadata information of the Pretrained Model([Faster R-CNN ResNet152 V1 640x640](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz)) from model zoo(https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) I used for training my model. It also has the same SignatureDef input shape: (1, -1, -1, 3). I suspect if this is the reason my final saved model has batchsize of 1 even after updating the exporter_lib_v2.py file. **I am facing issues to perform batch inferencing.**\r\n4. Also I checked the Tensorflow Serving Github Repo (https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_config.md#batching-configuration) and tried passing a separate batch.config while running the server but still could not perform batch inferencing. I used the below command - tensorflow_model_server --port=8500 --model_config_file=/data1/root/lab/prime_team_projects/scripts/models.config.a --enable_batching true --batching_parameters_file=/data1/root/lab/prime_team_projects/scripts/batch.config\r\n\r\nHelp me with this issue please.\r\n\r\n **System information**\r\n- OS Platform and Distribution:  Linux Ubuntu 18.04\r\n- TensorFlow installed from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\r\n- TensorFlow version (use command below): Latest 2.8\r\n- Python version: 3.7.10\r\n- CUDA/cuDNN version: 11.5\r\n- GPU model and memory: NVIDIA® V100, 32 GB\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10552/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10552/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10548","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10548/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10548/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10548/events","html_url":"https://github.com/tensorflow/models/issues/10548","id":1175479738,"node_id":"I_kwDOAwv_Dc5GEGW6","number":10548,"title":"VIT | switch off projection","user":{"login":"exx8","id":8540180,"node_id":"MDQ6VXNlcjg1NDAxODA=","avatar_url":"https://avatars.githubusercontent.com/u/8540180?v=4","gravatar_id":"","url":"https://api.github.com/users/exx8","html_url":"https://github.com/exx8","followers_url":"https://api.github.com/users/exx8/followers","following_url":"https://api.github.com/users/exx8/following{/other_user}","gists_url":"https://api.github.com/users/exx8/gists{/gist_id}","starred_url":"https://api.github.com/users/exx8/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/exx8/subscriptions","organizations_url":"https://api.github.com/users/exx8/orgs","repos_url":"https://api.github.com/users/exx8/repos","events_url":"https://api.github.com/users/exx8/events{/privacy}","received_events_url":"https://api.github.com/users/exx8/received_events","type":"User","site_admin":false},"labels":[{"id":473246400,"node_id":"MDU6TGFiZWw0NzMyNDY0MDA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:feature","name":"type:feature","color":"50bcc4","default":false,"description":""},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"xianzhidu","id":31711798,"node_id":"MDQ6VXNlcjMxNzExNzk4","avatar_url":"https://avatars.githubusercontent.com/u/31711798?v=4","gravatar_id":"","url":"https://api.github.com/users/xianzhidu","html_url":"https://github.com/xianzhidu","followers_url":"https://api.github.com/users/xianzhidu/followers","following_url":"https://api.github.com/users/xianzhidu/following{/other_user}","gists_url":"https://api.github.com/users/xianzhidu/gists{/gist_id}","starred_url":"https://api.github.com/users/xianzhidu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xianzhidu/subscriptions","organizations_url":"https://api.github.com/users/xianzhidu/orgs","repos_url":"https://api.github.com/users/xianzhidu/repos","events_url":"https://api.github.com/users/xianzhidu/events{/privacy}","received_events_url":"https://api.github.com/users/xianzhidu/received_events","type":"User","site_admin":false},"assignees":[{"login":"xianzhidu","id":31711798,"node_id":"MDQ6VXNlcjMxNzExNzk4","avatar_url":"https://avatars.githubusercontent.com/u/31711798?v=4","gravatar_id":"","url":"https://api.github.com/users/xianzhidu","html_url":"https://github.com/xianzhidu","followers_url":"https://api.github.com/users/xianzhidu/followers","following_url":"https://api.github.com/users/xianzhidu/following{/other_user}","gists_url":"https://api.github.com/users/xianzhidu/gists{/gist_id}","starred_url":"https://api.github.com/users/xianzhidu/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/xianzhidu/subscriptions","organizations_url":"https://api.github.com/users/xianzhidu/orgs","repos_url":"https://api.github.com/users/xianzhidu/repos","events_url":"https://api.github.com/users/xianzhidu/events{/privacy}","received_events_url":"https://api.github.com/users/xianzhidu/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-21T14:35:29Z","updated_at":"2022-03-21T17:52:27Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"body":"# Prerequisites\r\n\r\nPlease answer the following question for yourself before submitting an issue.\r\n\r\n- [X] I checked to make sure that this feature has not been requested already.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/blob/master/official/projects/vit/modeling/vit.py\r\n## 2. Describe the feature you request\r\n\r\nFor some feature types, especially of low dimension, projection doesn't suit.\r\nI wish that there were somehow to turn off the projection, so one can use directly the encoder.\r\nI tried to use the Encoder class directly, but it seems like an internal component and I get a funny error when I try to use it.\r\n## 3. Additional context\r\n\r\nAdd any other context about the feature request here.\r\n\r\n## 4. Are you willing to contribute it? (Yes or No)\r\nYes","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10548/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10548/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10543","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10543/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10543/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10543/events","html_url":"https://github.com/tensorflow/models/issues/10543","id":1173404523,"node_id":"I_kwDOAwv_Dc5F8Ltr","number":10543,"title":"TFOD 2.0 traing error","user":{"login":"amitsingha","id":13538136,"node_id":"MDQ6VXNlcjEzNTM4MTM2","avatar_url":"https://avatars.githubusercontent.com/u/13538136?v=4","gravatar_id":"","url":"https://api.github.com/users/amitsingha","html_url":"https://github.com/amitsingha","followers_url":"https://api.github.com/users/amitsingha/followers","following_url":"https://api.github.com/users/amitsingha/following{/other_user}","gists_url":"https://api.github.com/users/amitsingha/gists{/gist_id}","starred_url":"https://api.github.com/users/amitsingha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/amitsingha/subscriptions","organizations_url":"https://api.github.com/users/amitsingha/orgs","repos_url":"https://api.github.com/users/amitsingha/repos","events_url":"https://api.github.com/users/amitsingha/events{/privacy}","received_events_url":"https://api.github.com/users/amitsingha/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-18T09:58:51Z","updated_at":"2022-03-18T09:59:54Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"\r\n2022-03-18 08:32:39.542256: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nI0318 08:32:39.546747 139952984401792 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nINFO:tensorflow:Maybe overwriting train_steps: None\r\nI0318 08:32:39.552594 139952984401792 config_util.py:552] Maybe overwriting train_steps: None\r\nINFO:tensorflow:Maybe overwriting use_bfloat16: False\r\nI0318 08:32:39.552812 139952984401792 config_util.py:552] Maybe overwriting use_bfloat16: False\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nW0318 08:32:39.586458 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nrename to distribute_datasets_from_function\r\nINFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\r\nI0318 08:32:39.591196 139952984401792 dataset_builder.py:163] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\r\nINFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\r\nI0318 08:32:39.591431 139952984401792 dataset_builder.py:80] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\r\nINFO:tensorflow:Number of filenames to read: 1\r\nI0318 08:32:39.591586 139952984401792 dataset_builder.py:81] Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW0318 08:32:39.591766 139952984401792 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\r\nW0318 08:32:39.595097 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW0318 08:32:39.620530 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nW0318 08:32:48.658127 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW0318 08:32:52.709276 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0318 08:32:54.720247 139952984401792 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\n2022-03-18 08:32:59.009435: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\r\n2022-03-18 08:32:59.121557: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 90538332 exceeds 10% of free system memory.\r\n2022-03-18 08:32:59.122376: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 90538332 exceeds 10% of free system memory.\r\n2022-03-18 08:32:59.310427: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 90538332 exceeds 10% of free system memory.\r\n2022-03-18 08:32:59.579839: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 106696824 exceeds 10% of free system memory.\r\n2022-03-18 08:32:59.661944: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 106696824 exceeds 10% of free system memory.\r\n/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\r\n2022-03-18 08:33:26.941325: E tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\r\n2022-03-18 08:33:26.943324: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNKNOWN: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\nTraceback (most recent call last):\r\n  File \"model_main_tf2.py\", line 113, in <module>\r\n    tf.compat.v1.app.run()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main_tf2.py\", line 110, in main\r\n    record_summaries=FLAGS.record_summaries)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 609, in train_loop\r\n    train_input, unpad_groundtruth_tensors)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 400, in load_fine_tune_checkpoint\r\n    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\r\n  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 178, in _ensure_model_is_built\r\n    labels,\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1316, in run\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2892, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 678, in _call_for_each_replica\r\n    self._container_strategy(), fn, args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 86, in call_for_each_replica\r\n    return wrapped(args, kwargs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    inputs, attrs, num_outputs)\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D\r\n (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py:238)\r\n]] [Op:__inference__dummy_computation_fn_17350]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D:\r\nIn[0] args_1 (defined at /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:178)\t\r\nIn[1] ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D/ReadVariableOp:\r\n\r\nOperation defined at: (most recent call last)\r\n>>>   File \"/usr/lib/python3.7/threading.py\", line 890, in _bootstrap\r\n>>>     self._bootstrap_inner()\r\n>>> \r\n>>>   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\r\n>>>     self.run()\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 170, in _dummy_computation_fn\r\n>>>     return _compute_losses_and_predictions_dicts(model, features, labels,\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 123, in _compute_losses_and_predictions_dicts\r\n>>>     prediction_dict = model.predict(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 569, in predict\r\n>>>     if self._feature_extractor.is_keras_model:\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 570, in predict\r\n>>>     feature_maps = self._feature_extractor(preprocessed_inputs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 251, in call\r\n>>>     return self._extract_features(inputs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py\", line 219, in _extract_features\r\n>>>     image_features = self.classification_backbone(\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\r\n>>>     inputs, training=training, mask=mask)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\r\n>>>     outputs = node.layer(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\r\n>>>     outputs = call_fn(inputs, *args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\r\n>>>     return fn(*args, **kwargs)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 246, in call\r\n>>>     outputs = self.convolution_op(inputs, self.kernel)\r\n>>> \r\n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 238, in convolution_op\r\n>>>     name=self.__class__.__name__)\r\n\r\n**_### any solution for this problem? It's my first question here. forgive my mistake._**\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10543/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10543/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10540","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10540/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10540/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10540/events","html_url":"https://github.com/tensorflow/models/issues/10540","id":1172346733,"node_id":"I_kwDOAwv_Dc5F4Jdt","number":10540,"title":"Error while exporting efficientdet model with identity_resizer and anchor box normalization","user":{"login":"theVector1","id":45497925,"node_id":"MDQ6VXNlcjQ1NDk3OTI1","avatar_url":"https://avatars.githubusercontent.com/u/45497925?v=4","gravatar_id":"","url":"https://api.github.com/users/theVector1","html_url":"https://github.com/theVector1","followers_url":"https://api.github.com/users/theVector1/followers","following_url":"https://api.github.com/users/theVector1/following{/other_user}","gists_url":"https://api.github.com/users/theVector1/gists{/gist_id}","starred_url":"https://api.github.com/users/theVector1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/theVector1/subscriptions","organizations_url":"https://api.github.com/users/theVector1/orgs","repos_url":"https://api.github.com/users/theVector1/repos","events_url":"https://api.github.com/users/theVector1/events{/privacy}","received_events_url":"https://api.github.com/users/theVector1/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":{"login":"jvishnuvardhan","id":46058173,"node_id":"MDQ6VXNlcjQ2MDU4MTcz","avatar_url":"https://avatars.githubusercontent.com/u/46058173?v=4","gravatar_id":"","url":"https://api.github.com/users/jvishnuvardhan","html_url":"https://github.com/jvishnuvardhan","followers_url":"https://api.github.com/users/jvishnuvardhan/followers","following_url":"https://api.github.com/users/jvishnuvardhan/following{/other_user}","gists_url":"https://api.github.com/users/jvishnuvardhan/gists{/gist_id}","starred_url":"https://api.github.com/users/jvishnuvardhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jvishnuvardhan/subscriptions","organizations_url":"https://api.github.com/users/jvishnuvardhan/orgs","repos_url":"https://api.github.com/users/jvishnuvardhan/repos","events_url":"https://api.github.com/users/jvishnuvardhan/events{/privacy}","received_events_url":"https://api.github.com/users/jvishnuvardhan/received_events","type":"User","site_admin":false},"assignees":[{"login":"jvishnuvardhan","id":46058173,"node_id":"MDQ6VXNlcjQ2MDU4MTcz","avatar_url":"https://avatars.githubusercontent.com/u/46058173?v=4","gravatar_id":"","url":"https://api.github.com/users/jvishnuvardhan","html_url":"https://github.com/jvishnuvardhan","followers_url":"https://api.github.com/users/jvishnuvardhan/followers","following_url":"https://api.github.com/users/jvishnuvardhan/following{/other_user}","gists_url":"https://api.github.com/users/jvishnuvardhan/gists{/gist_id}","starred_url":"https://api.github.com/users/jvishnuvardhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jvishnuvardhan/subscriptions","organizations_url":"https://api.github.com/users/jvishnuvardhan/orgs","repos_url":"https://api.github.com/users/jvishnuvardhan/repos","events_url":"https://api.github.com/users/jvishnuvardhan/events{/privacy}","received_events_url":"https://api.github.com/users/jvishnuvardhan/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-17T12:54:37Z","updated_at":"2022-03-18T16:52:09Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hello everyone,\r\n\r\nwhile exporting efficientdet with _identity_resizer_ using exporter_main_v2.py, I'm facing the following error:\r\n\r\n```\r\nException has occurred: ValueError\r\nin user code:\r\n\r\n    [/training/tf_models/research/object_detection/exporter_lib_v2.py]():191 __call__  *\r\n        true_shapes)\r\n    /training/tf_models/research/object_detection/exporter_lib_v2.py:126 _run_inference_on_images  *\r\n        prediction_dict = self._model.predict(images, true_shapes, **kwargs)\r\n    /training/tf_models/research/object_detection/meta_architectures/ssd_meta_arch.py:585 predict  *\r\n        boxlist_list = self._anchor_generator.generate(\r\n    /training/tf_models/research/object_detection/core/anchor_generator.py:107 generate  *\r\n        anchors_list = self._generate(feature_map_shape_list, **params)\r\n    /training/tf_models/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py:144 _generate  *\r\n        raise ValueError(\r\n\r\n    ValueError: Normalized coordinates were requested upon construction of the MultiscaleGridAnchorGenerator, but a subsequent call to generate did not supply dimension information.\r\n  File \"/training/tf_models/research/object_detection/exporter_lib_v2.py\", line 272, in export_inference_graph\r\n    concrete_function = detection_module.__call__.get_concrete_function()\r\n  File \"[/training/tf_models/research/object_detection/exporter_main_v2.py]()\", line 161, in main\r\n    FLAGS.side_input_types, FLAGS.side_input_names)\r\n  File \"[/training/tf_models/research/object_detection/exporter_main_v2.py]()\", line 167, in <module>\r\n    app.run(main) \r\n```\r\n\r\n\r\n\r\nhere is the config I'm using for exporting the efficientdet.\r\n\r\n```\r\nmodel {\r\n  ssd {\r\n    num_classes: 8\r\n    image_resizer {\r\n       identity_resizer{}\r\n    }\r\n    feature_extractor {\r\n      type: \"ssd_efficientnet-b3_bifpn_keras\"\r\n      #pad_to_multiple: 128\r\n      conv_hyperparams {\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 3.9999998989515007e-05\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            mean: 0.0\r\n            stddev: 0.03\r\n          }\r\n        }\r\n        activation: SWISH\r\n        batch_norm {\r\n          decay: 0.99\r\n          scale: true\r\n          epsilon: 0.001\r\n        }\r\n        force_use_bias: true\r\n      }\r\n      bifpn {\r\n        min_level: 3\r\n        max_level: 7\r\n        num_iterations: 6\r\n        num_filters: 160\r\n      }\r\n    }\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 1.0\r\n        x_scale: 1.0\r\n        height_scale: 1.0\r\n        width_scale: 1.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n        use_matmul_gather: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    box_predictor {\r\n      weight_shared_convolutional_box_predictor {\r\n        conv_hyperparams {\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 3.9999998989515007e-05\r\n            }\r\n          }\r\n          initializer {\r\n            random_normal_initializer {\r\n              mean: 0.0\r\n              stddev: 0.01\r\n            }\r\n          }\r\n          activation: SWISH\r\n          batch_norm {\r\n            decay: 0.99\r\n            scale: true\r\n            epsilon: 0.001\r\n          }\r\n          force_use_bias: true\r\n        }\r\n        depth: 160\r\n        num_layers_before_predictor: 4\r\n        kernel_size: 3\r\n        class_prediction_bias_init: -4.6\r\n        use_depthwise: true\r\n      }\r\n    }\r\n    anchor_generator {\r\n      multiscale_anchor_generator {\r\n        min_level: 3\r\n        max_level: 7\r\n        anchor_scale: 4.0\r\n        aspect_ratios: [1.0, 2.0, 0.5]\r\n        scales_per_octave: 3\r\n        #normalize_coordinates: false\r\n      }\r\n    }\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 9.99999993922529e-09\r\n        iou_threshold: 0.5\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    loss {\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      classification_loss {\r\n        weighted_sigmoid_focal {\r\n          gamma: 1.5\r\n          alpha: 0.25\r\n        }\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 2.0\r\n    }\r\n    encode_background_as_zeros: true\r\n    normalize_loc_loss_by_codesize: true\r\n    inplace_batchnorm_update: true\r\n    freeze_batchnorm: false\r\n    add_background_class: false\r\n  }\r\n}\r\n```\r\n\r\n\r\n\r\nIt seems that the TF2 code could not construct the normalization of anchor coordinates while tracing the graph, since _identity_resizer_'s output is of dynamic shape. Does anyone know how to resolve this problem? Any help is much appreciated.\r\n\r\nThanks a lot!\r\n\r\n## System information\r\n\r\n- OS Platform and Distribution: CentOS 7 rhel fedora\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.6.2\r\n- Python version: 2.7.5\r\n\r\n- CUDA/cuDNN version: 11.4\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10540/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10540/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10538","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10538/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10538/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10538/events","html_url":"https://github.com/tensorflow/models/issues/10538","id":1170960131,"node_id":"I_kwDOAwv_Dc5Fy28D","number":10538,"title":"Utilise 100% GPU resource for YOLO v3 detection using TensorFlow","user":{"login":"Shubham-cat4","id":100746991,"node_id":"U_kgDOBgFG7w","avatar_url":"https://avatars.githubusercontent.com/u/100746991?v=4","gravatar_id":"","url":"https://api.github.com/users/Shubham-cat4","html_url":"https://github.com/Shubham-cat4","followers_url":"https://api.github.com/users/Shubham-cat4/followers","following_url":"https://api.github.com/users/Shubham-cat4/following{/other_user}","gists_url":"https://api.github.com/users/Shubham-cat4/gists{/gist_id}","starred_url":"https://api.github.com/users/Shubham-cat4/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shubham-cat4/subscriptions","organizations_url":"https://api.github.com/users/Shubham-cat4/orgs","repos_url":"https://api.github.com/users/Shubham-cat4/repos","events_url":"https://api.github.com/users/Shubham-cat4/events{/privacy}","received_events_url":"https://api.github.com/users/Shubham-cat4/received_events","type":"User","site_admin":false},"labels":[{"id":473246400,"node_id":"MDU6TGFiZWw0NzMyNDY0MDA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:feature","name":"type:feature","color":"50bcc4","default":false,"description":""},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},"assignees":[{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},{"login":"saberkun","id":4873189,"node_id":"MDQ6VXNlcjQ4NzMxODk=","avatar_url":"https://avatars.githubusercontent.com/u/4873189?v=4","gravatar_id":"","url":"https://api.github.com/users/saberkun","html_url":"https://github.com/saberkun","followers_url":"https://api.github.com/users/saberkun/followers","following_url":"https://api.github.com/users/saberkun/following{/other_user}","gists_url":"https://api.github.com/users/saberkun/gists{/gist_id}","starred_url":"https://api.github.com/users/saberkun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saberkun/subscriptions","organizations_url":"https://api.github.com/users/saberkun/orgs","repos_url":"https://api.github.com/users/saberkun/repos","events_url":"https://api.github.com/users/saberkun/events{/privacy}","received_events_url":"https://api.github.com/users/saberkun/received_events","type":"User","site_admin":false},{"login":"rachellj218","id":42055825,"node_id":"MDQ6VXNlcjQyMDU1ODI1","avatar_url":"https://avatars.githubusercontent.com/u/42055825?v=4","gravatar_id":"","url":"https://api.github.com/users/rachellj218","html_url":"https://github.com/rachellj218","followers_url":"https://api.github.com/users/rachellj218/followers","following_url":"https://api.github.com/users/rachellj218/following{/other_user}","gists_url":"https://api.github.com/users/rachellj218/gists{/gist_id}","starred_url":"https://api.github.com/users/rachellj218/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rachellj218/subscriptions","organizations_url":"https://api.github.com/users/rachellj218/orgs","repos_url":"https://api.github.com/users/rachellj218/repos","events_url":"https://api.github.com/users/rachellj218/events{/privacy}","received_events_url":"https://api.github.com/users/rachellj218/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-16T12:30:53Z","updated_at":"2022-03-21T12:47:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"My System Configuration : I'm working on a Yolov3 model with GeForce RTX 2080 Ti GPU with 11 GB GPU memory and Intel (R) Core (TM) i9-9900KF CPU with 6 cores and 64GB of RAM.\r\n\r\nWhen i inference on images, my average FPS is between 35 FPS and GPU utilisation is 1128MiB (~1GB out of 11GB). I use TensorFlow and convert + loading the yolov3 model on the GPU\r\n\r\nI am able to increase the volume of image inference by running the same setup in 6 instances and I am able to achieve 210 FPS and GPU utilisation is 6760MiB (~6GB out of 11GB). However, this method requires me to separate the images and feed non duplicate entries to each of the 6 instances.\r\n\r\nHow do I run a single instance that utilises the full GPU so I can extract the best FPS from all the 11 GB of GPU.","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10538/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10538/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10537","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10537/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10537/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10537/events","html_url":"https://github.com/tensorflow/models/pull/10537","id":1170689922,"node_id":"PR_kwDOAwv_Dc40hAEO","number":10537,"title":"Added Panoptic deeplab","user":{"login":"srihari-humbarwadi","id":24864163,"node_id":"MDQ6VXNlcjI0ODY0MTYz","avatar_url":"https://avatars.githubusercontent.com/u/24864163?v=4","gravatar_id":"","url":"https://api.github.com/users/srihari-humbarwadi","html_url":"https://github.com/srihari-humbarwadi","followers_url":"https://api.github.com/users/srihari-humbarwadi/followers","following_url":"https://api.github.com/users/srihari-humbarwadi/following{/other_user}","gists_url":"https://api.github.com/users/srihari-humbarwadi/gists{/gist_id}","starred_url":"https://api.github.com/users/srihari-humbarwadi/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/srihari-humbarwadi/subscriptions","organizations_url":"https://api.github.com/users/srihari-humbarwadi/orgs","repos_url":"https://api.github.com/users/srihari-humbarwadi/repos","events_url":"https://api.github.com/users/srihari-humbarwadi/events{/privacy}","received_events_url":"https://api.github.com/users/srihari-humbarwadi/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2022-03-16T08:23:45Z","updated_at":"2022-03-31T12:53:56Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/tensorflow/models/pulls/10537","html_url":"https://github.com/tensorflow/models/pull/10537","diff_url":"https://github.com/tensorflow/models/pull/10537.diff","patch_url":"https://github.com/tensorflow/models/pull/10537.patch","merged_at":null},"body":"# Description\r\nThis PR adds the Panoptic Deeplab architecture described in  [Panoptic-DeepLab\r\n](https://arxiv.org/pdf/1911.10194.pdf)\r\n\r\n## Type of change\r\n- [x] A new research paper code implementation\r\n\r\n## Tests\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.heads.panoptic_deeplab_heads_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.factory_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.panoptic_deeplab_model_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.modeling.layers.panoptic_deeplab_merge_test`\r\n  - `python -m official.vision.beta.projects.panoptic_maskrcnn.tasks.panoptic_deeplab_test`\r\n\r\n## Checklist\r\n\r\n- [x] I have signed the [Contributor License Agreement](https://github.com/tensorflow/models/wiki/Contributor-License-Agreements).\r\n- [x] I have read [guidelines for pull request](https://github.com/tensorflow/models/wiki/Submitting-a-pull-request).\r\n- [x] My code follows the [coding guidelines](https://github.com/tensorflow/models/wiki/Coding-guidelines).\r\n- [x] I have performed a self [code review](https://github.com/tensorflow/models/wiki/Code-review) of my own code.\r\n- [x] I have commented my code, particularly in hard-to-understand areas.\r\n- [ ] I have made corresponding changes to the documentation.\r\n- [x] My changes generate no new warnings.\r\n- [x] I have added tests that prove my fix is effective or that my feature works.\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10537/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10537/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10536","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10536/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10536/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10536/events","html_url":"https://github.com/tensorflow/models/issues/10536","id":1166556226,"node_id":"I_kwDOAwv_Dc5FiDxC","number":10536,"title":"google.protobuf.text_format.ParseError: 90:6 : Message type \"object_detection.protos.Ssd\" has no field named \"google","user":{"login":"Tom12325","id":98054435,"node_id":"U_kgDOBdgxIw","avatar_url":"https://avatars.githubusercontent.com/u/98054435?v=4","gravatar_id":"","url":"https://api.github.com/users/Tom12325","html_url":"https://github.com/Tom12325","followers_url":"https://api.github.com/users/Tom12325/followers","following_url":"https://api.github.com/users/Tom12325/following{/other_user}","gists_url":"https://api.github.com/users/Tom12325/gists{/gist_id}","starred_url":"https://api.github.com/users/Tom12325/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Tom12325/subscriptions","organizations_url":"https://api.github.com/users/Tom12325/orgs","repos_url":"https://api.github.com/users/Tom12325/repos","events_url":"https://api.github.com/users/Tom12325/events{/privacy}","received_events_url":"https://api.github.com/users/Tom12325/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},"assignees":[{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},{"login":"jch1","id":1811449,"node_id":"MDQ6VXNlcjE4MTE0NDk=","avatar_url":"https://avatars.githubusercontent.com/u/1811449?v=4","gravatar_id":"","url":"https://api.github.com/users/jch1","html_url":"https://github.com/jch1","followers_url":"https://api.github.com/users/jch1/followers","following_url":"https://api.github.com/users/jch1/following{/other_user}","gists_url":"https://api.github.com/users/jch1/gists{/gist_id}","starred_url":"https://api.github.com/users/jch1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jch1/subscriptions","organizations_url":"https://api.github.com/users/jch1/orgs","repos_url":"https://api.github.com/users/jch1/repos","events_url":"https://api.github.com/users/jch1/events{/privacy}","received_events_url":"https://api.github.com/users/jch1/received_events","type":"User","site_admin":false},{"login":"pkulzc","id":35853368,"node_id":"MDQ6VXNlcjM1ODUzMzY4","avatar_url":"https://avatars.githubusercontent.com/u/35853368?v=4","gravatar_id":"","url":"https://api.github.com/users/pkulzc","html_url":"https://github.com/pkulzc","followers_url":"https://api.github.com/users/pkulzc/followers","following_url":"https://api.github.com/users/pkulzc/following{/other_user}","gists_url":"https://api.github.com/users/pkulzc/gists{/gist_id}","starred_url":"https://api.github.com/users/pkulzc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkulzc/subscriptions","organizations_url":"https://api.github.com/users/pkulzc/orgs","repos_url":"https://api.github.com/users/pkulzc/repos","events_url":"https://api.github.com/users/pkulzc/events{/privacy}","received_events_url":"https://api.github.com/users/pkulzc/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2022-03-11T15:28:28Z","updated_at":"2022-03-15T14:58:18Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi, i am trying to train an object detection model and keep getting the following error.\r\n\r\nTraceback (most recent call last):\r\n  File \"model_main.py\", line 125, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 312, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 258, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"model_main.py\", line 87, in main\r\n    FLAGS.sample_1_of_n_eval_on_train_examples))\r\n  File \"/home/indus/.local/lib/python3.6/site-packages/object_detection/model_lib.py\", line 829, in create_estimator_and_inputs\r\n    pipeline_config_path, config_override=config_override)\r\n  File \"/home/indus/.local/lib/python3.6/site-packages/object_detection/utils/config_util.py\", line 139, in get_configs_from_pipeline_file\r\n    text_format.Merge(proto_str, pipeline_config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 725, in Merge\r\n    allow_unknown_field=allow_unknown_field)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 793, in MergeLines\r\n    return parser.MergeLines(lines, message)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 818, in MergeLines\r\n    self._ParseOrMerge(lines, message)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 837, in _ParseOrMerge\r\n    self._MergeField(tokenizer, message)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 967, in _MergeField\r\n    merger(tokenizer, message, field)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 1042, in _MergeMessageField\r\n    self._MergeField(tokenizer, sub_message)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 967, in _MergeField\r\n    merger(tokenizer, message, field)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 1042, in _MergeMessageField\r\n    self._MergeField(tokenizer, sub_message)\r\n  File \"/usr/local/lib/python3.6/dist-packages/google/protobuf/text_format.py\", line 934, in _MergeField\r\n    (message_descriptor.full_name, name))\r\ngoogle.protobuf.text_format.ParseError: 90:6 : Message type \"object_detection.protos.Ssd\" has no field named \"google\".\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10536/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10536/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10535","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10535/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10535/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10535/events","html_url":"https://github.com/tensorflow/models/issues/10535","id":1166375607,"node_id":"I_kwDOAwv_Dc5FhXq3","number":10535,"title":"Generate SSD anchor box aspect ratios using k-means clustering Tutorial for TF1 ?","user":{"login":"Petros626","id":62354721,"node_id":"MDQ6VXNlcjYyMzU0NzIx","avatar_url":"https://avatars.githubusercontent.com/u/62354721?v=4","gravatar_id":"","url":"https://api.github.com/users/Petros626","html_url":"https://github.com/Petros626","followers_url":"https://api.github.com/users/Petros626/followers","following_url":"https://api.github.com/users/Petros626/following{/other_user}","gists_url":"https://api.github.com/users/Petros626/gists{/gist_id}","starred_url":"https://api.github.com/users/Petros626/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Petros626/subscriptions","organizations_url":"https://api.github.com/users/Petros626/orgs","repos_url":"https://api.github.com/users/Petros626/repos","events_url":"https://api.github.com/users/Petros626/events{/privacy}","received_events_url":"https://api.github.com/users/Petros626/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},"assignees":[{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},{"login":"jch1","id":1811449,"node_id":"MDQ6VXNlcjE4MTE0NDk=","avatar_url":"https://avatars.githubusercontent.com/u/1811449?v=4","gravatar_id":"","url":"https://api.github.com/users/jch1","html_url":"https://github.com/jch1","followers_url":"https://api.github.com/users/jch1/followers","following_url":"https://api.github.com/users/jch1/following{/other_user}","gists_url":"https://api.github.com/users/jch1/gists{/gist_id}","starred_url":"https://api.github.com/users/jch1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jch1/subscriptions","organizations_url":"https://api.github.com/users/jch1/orgs","repos_url":"https://api.github.com/users/jch1/repos","events_url":"https://api.github.com/users/jch1/events{/privacy}","received_events_url":"https://api.github.com/users/jch1/received_events","type":"User","site_admin":false},{"login":"pkulzc","id":35853368,"node_id":"MDQ6VXNlcjM1ODUzMzY4","avatar_url":"https://avatars.githubusercontent.com/u/35853368?v=4","gravatar_id":"","url":"https://api.github.com/users/pkulzc","html_url":"https://github.com/pkulzc","followers_url":"https://api.github.com/users/pkulzc/followers","following_url":"https://api.github.com/users/pkulzc/following{/other_user}","gists_url":"https://api.github.com/users/pkulzc/gists{/gist_id}","starred_url":"https://api.github.com/users/pkulzc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkulzc/subscriptions","organizations_url":"https://api.github.com/users/pkulzc/orgs","repos_url":"https://api.github.com/users/pkulzc/repos","events_url":"https://api.github.com/users/pkulzc/events{/privacy}","received_events_url":"https://api.github.com/users/pkulzc/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-11T12:44:00Z","updated_at":"2022-03-14T17:09:17Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"hey guys,\r\n\r\ni wanted to ask if this tutorial also creates a compatible **pipeline config file** for **TensorFlow 1** SSDs or if it is **only for TensorFlow 2.**\r\n\r\nTutorial:\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/generate_ssd_anchor_box_aspect_ratios_using_k_means_clustering.ipynb\r\n\r\nthanks a lot","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10535/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10535/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10534","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10534/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10534/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10534/events","html_url":"https://github.com/tensorflow/models/issues/10534","id":1166192161,"node_id":"I_kwDOAwv_Dc5Fgq4h","number":10534,"title":"Running out of memory because of large input data (individual file) size, stuck at epoch 1/X","user":{"login":"Alimarashli","id":48861707,"node_id":"MDQ6VXNlcjQ4ODYxNzA3","avatar_url":"https://avatars.githubusercontent.com/u/48861707?v=4","gravatar_id":"","url":"https://api.github.com/users/Alimarashli","html_url":"https://github.com/Alimarashli","followers_url":"https://api.github.com/users/Alimarashli/followers","following_url":"https://api.github.com/users/Alimarashli/following{/other_user}","gists_url":"https://api.github.com/users/Alimarashli/gists{/gist_id}","starred_url":"https://api.github.com/users/Alimarashli/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Alimarashli/subscriptions","organizations_url":"https://api.github.com/users/Alimarashli/orgs","repos_url":"https://api.github.com/users/Alimarashli/repos","events_url":"https://api.github.com/users/Alimarashli/events{/privacy}","received_events_url":"https://api.github.com/users/Alimarashli/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},"assignees":[{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},{"login":"saberkun","id":4873189,"node_id":"MDQ6VXNlcjQ4NzMxODk=","avatar_url":"https://avatars.githubusercontent.com/u/4873189?v=4","gravatar_id":"","url":"https://api.github.com/users/saberkun","html_url":"https://github.com/saberkun","followers_url":"https://api.github.com/users/saberkun/followers","following_url":"https://api.github.com/users/saberkun/following{/other_user}","gists_url":"https://api.github.com/users/saberkun/gists{/gist_id}","starred_url":"https://api.github.com/users/saberkun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saberkun/subscriptions","organizations_url":"https://api.github.com/users/saberkun/orgs","repos_url":"https://api.github.com/users/saberkun/repos","events_url":"https://api.github.com/users/saberkun/events{/privacy}","received_events_url":"https://api.github.com/users/saberkun/received_events","type":"User","site_admin":false},{"login":"rachellj218","id":42055825,"node_id":"MDQ6VXNlcjQyMDU1ODI1","avatar_url":"https://avatars.githubusercontent.com/u/42055825?v=4","gravatar_id":"","url":"https://api.github.com/users/rachellj218","html_url":"https://github.com/rachellj218","followers_url":"https://api.github.com/users/rachellj218/followers","following_url":"https://api.github.com/users/rachellj218/following{/other_user}","gists_url":"https://api.github.com/users/rachellj218/gists{/gist_id}","starred_url":"https://api.github.com/users/rachellj218/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rachellj218/subscriptions","organizations_url":"https://api.github.com/users/rachellj218/orgs","repos_url":"https://api.github.com/users/rachellj218/repos","events_url":"https://api.github.com/users/rachellj218/events{/privacy}","received_events_url":"https://api.github.com/users/rachellj218/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2022-03-11T09:28:59Z","updated_at":"2022-03-15T14:57:39Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\n\r\nI am training a Conv1D autoencoder but when I try to apply model.fit() it gets stuck at epoch1/2 regardless of how small the batch size is. When running on Colab, with random data of the same size, it runs out of memory and disconnects (not sure if GPU RAM or normal RAM)\r\nThe code runs for smaller data and I also tried it on my personal workstation with RTX 3090 and 128GB of memory.\r\n I am not sure what I can do to fix the issue, the data size is only 4MB, while GPU memory is 24GB and PC memory is 128GB but even with a dataset of 2 and batch size of 2 it still gets stuck. \r\ncode and colab link: \r\nhttps://colab.research.google.com/drive/1KL3tYnJc8rNn-5eqIPtdQrheogfwic0h?usp=sharing \r\n`\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nfrom tensorflow.keras.models import Sequential,Model\r\nfrom tensorflow.keras.layers import Input,Dense,Conv1D,MaxPooling1D,UpSampling1D,Flatten,add,Cropping1D\r\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Cropping2D,Reshape\r\n\r\n\r\ndef cnn1D(loss='mse',optimizer='adam',activation0='relu',activation='linear',x_shape=(531441,1),pooling1=3,pooling2=3,filter1=64,filter2=64,kernel=3):\r\n    \r\n    in_dim = x_shape\r\n    input_img = Input(shape=in_dim) #input layer\r\n    #conv1\r\n    x1 = Conv1D(filter1, kernel, activation=activation0, padding='same')(input_img) # 100 100 64 \r\n    x2 = MaxPooling1D(pooling1, padding='same')(x1) # 50 50 64\r\n    #conv2\r\n    x2 = Conv1D(filter2, kernel, activation=activation0, padding='same')(x2) # 50 50 128\r\n    x3 = MaxPooling1D(pooling2, padding='same')(x2) # 25 25 128\r\n    \r\n\r\n    #de-conv2\r\n    encoded = Conv1D(filter2, kernel, activation=activation0, padding='same')(x3) # 25 25 128\r\n    y=UpSampling1D(pooling2)(encoded) # 50 50 128\r\n    \r\n\r\n    #de-conv1\r\n    y=Conv1D(filter1, kernel, activation=activation0, padding='same')(y) # 50 50 128\r\n    y=UpSampling1D(pooling1)(y) # 100 100 128\r\n\r\n\r\n    decoded = Conv1D(x_shape[-1], 11, activation=activation, padding='same')(y) # 100 100 4\r\n\r\n    cnn = Model(input_img, decoded)\r\n\r\n    cnn.compile(loss=loss,optimizer=optimizer)#,metrics=['accuracy']) #adadelta\r\n    cnn.summary()\r\n    return cnn\r\nnn2 = cnn1D()\r\n\r\nimport numpy as np\r\n\r\ntraining_dataset = np.random.normal(size=(10,531441, 1))\r\n\r\nnn2.fit(training_dataset, training_dataset, epochs=2, batch_size=2,validation_data=(training_dataset,training_dataset))\r\n\r\n```\r\n`\r\nNote: I come from physics background so sorry if the answer is obvious and I did something wrong","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10534/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10534/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10533","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10533/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10533/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10533/events","html_url":"https://github.com/tensorflow/models/issues/10533","id":1164789870,"node_id":"I_kwDOAwv_Dc5FbUhu","number":10533,"title":" I am planning to add class weights to give extra weightage for my classes which has lesser count. I got the concept but I am stuck with where to add this. Can I add this in pipeline config file?? If yes where?. ","user":{"login":"athithya-raj","id":95672442,"node_id":"U_kgDOBbPYeg","avatar_url":"https://avatars.githubusercontent.com/u/95672442?v=4","gravatar_id":"","url":"https://api.github.com/users/athithya-raj","html_url":"https://github.com/athithya-raj","followers_url":"https://api.github.com/users/athithya-raj/followers","following_url":"https://api.github.com/users/athithya-raj/following{/other_user}","gists_url":"https://api.github.com/users/athithya-raj/gists{/gist_id}","starred_url":"https://api.github.com/users/athithya-raj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/athithya-raj/subscriptions","organizations_url":"https://api.github.com/users/athithya-raj/orgs","repos_url":"https://api.github.com/users/athithya-raj/repos","events_url":"https://api.github.com/users/athithya-raj/events{/privacy}","received_events_url":"https://api.github.com/users/athithya-raj/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},"assignees":[{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},{"login":"jch1","id":1811449,"node_id":"MDQ6VXNlcjE4MTE0NDk=","avatar_url":"https://avatars.githubusercontent.com/u/1811449?v=4","gravatar_id":"","url":"https://api.github.com/users/jch1","html_url":"https://github.com/jch1","followers_url":"https://api.github.com/users/jch1/followers","following_url":"https://api.github.com/users/jch1/following{/other_user}","gists_url":"https://api.github.com/users/jch1/gists{/gist_id}","starred_url":"https://api.github.com/users/jch1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jch1/subscriptions","organizations_url":"https://api.github.com/users/jch1/orgs","repos_url":"https://api.github.com/users/jch1/repos","events_url":"https://api.github.com/users/jch1/events{/privacy}","received_events_url":"https://api.github.com/users/jch1/received_events","type":"User","site_admin":false},{"login":"pkulzc","id":35853368,"node_id":"MDQ6VXNlcjM1ODUzMzY4","avatar_url":"https://avatars.githubusercontent.com/u/35853368?v=4","gravatar_id":"","url":"https://api.github.com/users/pkulzc","html_url":"https://github.com/pkulzc","followers_url":"https://api.github.com/users/pkulzc/followers","following_url":"https://api.github.com/users/pkulzc/following{/other_user}","gists_url":"https://api.github.com/users/pkulzc/gists{/gist_id}","starred_url":"https://api.github.com/users/pkulzc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkulzc/subscriptions","organizations_url":"https://api.github.com/users/pkulzc/orgs","repos_url":"https://api.github.com/users/pkulzc/repos","events_url":"https://api.github.com/users/pkulzc/events{/privacy}","received_events_url":"https://api.github.com/users/pkulzc/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-10T06:01:13Z","updated_at":"2022-03-14T17:08:15Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I am training EfficienDet D4 on my custom dataset using TensorFlow Object Detection API, I have an imbalanced dataset so, I am planning to add class weights to give extra weightage for my classes which has lesser count. I got the concept but I am stuck with where to add this. Can I add this in pipeline config file?? If yes where?. Otherwise which is the file where model.fit lies. Please give suggestions. Or if there is better way of doing this, please let me know. [where does class_weights or weighted loss penalize the network?](https://stackoverflow.com/questions/65417379/where-does-class-weights-or-weighted-loss-penalize-the-network) Actually I want to implement the solutions from the above link","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10533/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10533/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10531","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10531/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10531/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10531/events","html_url":"https://github.com/tensorflow/models/pull/10531","id":1163591925,"node_id":"PR_kwDOAwv_Dc40J3xe","number":10531,"title":"Updated learning rate and warmup_learning_rate","user":{"login":"jvishnuvardhan","id":46058173,"node_id":"MDQ6VXNlcjQ2MDU4MTcz","avatar_url":"https://avatars.githubusercontent.com/u/46058173?v=4","gravatar_id":"","url":"https://api.github.com/users/jvishnuvardhan","html_url":"https://github.com/jvishnuvardhan","followers_url":"https://api.github.com/users/jvishnuvardhan/followers","following_url":"https://api.github.com/users/jvishnuvardhan/following{/other_user}","gists_url":"https://api.github.com/users/jvishnuvardhan/gists{/gist_id}","starred_url":"https://api.github.com/users/jvishnuvardhan/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jvishnuvardhan/subscriptions","organizations_url":"https://api.github.com/users/jvishnuvardhan/orgs","repos_url":"https://api.github.com/users/jvishnuvardhan/repos","events_url":"https://api.github.com/users/jvishnuvardhan/events{/privacy}","received_events_url":"https://api.github.com/users/jvishnuvardhan/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2022-03-09T07:38:21Z","updated_at":"2022-03-09T07:42:19Z","closed_at":null,"author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https://api.github.com/repos/tensorflow/models/pulls/10531","html_url":"https://github.com/tensorflow/models/pull/10531","diff_url":"https://github.com/tensorflow/models/pull/10531.diff","patch_url":"https://github.com/tensorflow/models/pull/10531.patch","merged_at":null},"body":"Looks like this is a typo. All the other models uses small learning rate excepti this specific model. As the user mentioned below, the loss spikes with this learning rate.\r\n\r\nUpdated learning rate and warmup_learning_rate based on the following GH issue\r\n\r\nFixes https://github.com/tensorflow/models/issues/10509\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10531/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10531/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10530","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10530/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10530/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10530/events","html_url":"https://github.com/tensorflow/models/issues/10530","id":1162843331,"node_id":"I_kwDOAwv_Dc5FT5TD","number":10530,"title":"How to train on COCO dataset and achieve same mAP as the reported one?","user":{"login":"kikefdezl","id":75074147,"node_id":"MDQ6VXNlcjc1MDc0MTQ3","avatar_url":"https://avatars.githubusercontent.com/u/75074147?v=4","gravatar_id":"","url":"https://api.github.com/users/kikefdezl","html_url":"https://github.com/kikefdezl","followers_url":"https://api.github.com/users/kikefdezl/followers","following_url":"https://api.github.com/users/kikefdezl/following{/other_user}","gists_url":"https://api.github.com/users/kikefdezl/gists{/gist_id}","starred_url":"https://api.github.com/users/kikefdezl/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/kikefdezl/subscriptions","organizations_url":"https://api.github.com/users/kikefdezl/orgs","repos_url":"https://api.github.com/users/kikefdezl/repos","events_url":"https://api.github.com/users/kikefdezl/events{/privacy}","received_events_url":"https://api.github.com/users/kikefdezl/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},"assignees":[{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},{"login":"jch1","id":1811449,"node_id":"MDQ6VXNlcjE4MTE0NDk=","avatar_url":"https://avatars.githubusercontent.com/u/1811449?v=4","gravatar_id":"","url":"https://api.github.com/users/jch1","html_url":"https://github.com/jch1","followers_url":"https://api.github.com/users/jch1/followers","following_url":"https://api.github.com/users/jch1/following{/other_user}","gists_url":"https://api.github.com/users/jch1/gists{/gist_id}","starred_url":"https://api.github.com/users/jch1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jch1/subscriptions","organizations_url":"https://api.github.com/users/jch1/orgs","repos_url":"https://api.github.com/users/jch1/repos","events_url":"https://api.github.com/users/jch1/events{/privacy}","received_events_url":"https://api.github.com/users/jch1/received_events","type":"User","site_admin":false},{"login":"pkulzc","id":35853368,"node_id":"MDQ6VXNlcjM1ODUzMzY4","avatar_url":"https://avatars.githubusercontent.com/u/35853368?v=4","gravatar_id":"","url":"https://api.github.com/users/pkulzc","html_url":"https://github.com/pkulzc","followers_url":"https://api.github.com/users/pkulzc/followers","following_url":"https://api.github.com/users/pkulzc/following{/other_user}","gists_url":"https://api.github.com/users/pkulzc/gists{/gist_id}","starred_url":"https://api.github.com/users/pkulzc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkulzc/subscriptions","organizations_url":"https://api.github.com/users/pkulzc/orgs","repos_url":"https://api.github.com/users/pkulzc/repos","events_url":"https://api.github.com/users/pkulzc/events{/privacy}","received_events_url":"https://api.github.com/users/pkulzc/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-08T16:09:53Z","updated_at":"2022-03-11T03:33:03Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"I'm trying to reproduce the officially reported mAP of EfficientDet D3 in the Object Detection API by training on COCO using a pretrained EfficientNet backbone. The official COCO mAP is [45.4%](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and yet all I can manage to achieve is around 14%. I don't need to reach the same value, but I wish to at least come close to it.\r\n\r\nI am loading the EfficientNet B3 checkpoint pretrained on ImageNet found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_classification_zoo.md), and using the config file found [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2). The only parameters I changed are batch size (to fit into an RTX 3090), learning rate (0.08 was yielding loss=NaN so I reduced it to 0.01), and steps, which I increased to 600k. This is my pipeline.config file:\r\n\r\n```\r\nmodel {\r\n  ssd {\r\n    inplace_batchnorm_update: true\r\n    freeze_batchnorm: false\r\n    num_classes: 90\r\n    add_background_class: false\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n        use_matmul_gather: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    encode_background_as_zeros: true\r\n    anchor_generator {\r\n      multiscale_anchor_generator {\r\n        min_level: 3\r\n        max_level: 7\r\n        anchor_scale: 4.0\r\n        aspect_ratios: [1.0, 2.0, 0.5]\r\n        scales_per_octave: 3\r\n      }\r\n    }\r\n    image_resizer {\r\n      keep_aspect_ratio_resizer {\r\n        min_dimension: 896\r\n        max_dimension: 896\r\n        pad_to_max_dimension: true\r\n        }\r\n    }\r\n    box_predictor {\r\n      weight_shared_convolutional_box_predictor {\r\n        depth: 160\r\n        class_prediction_bias_init: -4.6\r\n        conv_hyperparams {\r\n          force_use_bias: true\r\n          activation: SWISH\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            random_normal_initializer {\r\n              stddev: 0.01\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            scale: true\r\n            decay: 0.99\r\n            epsilon: 0.001\r\n          }\r\n        }\r\n        num_layers_before_predictor: 4\r\n        kernel_size: 3\r\n        use_depthwise: true\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_efficientnet-b3_bifpn_keras'\r\n      bifpn {\r\n        min_level: 3\r\n        max_level: 7\r\n        num_iterations: 6\r\n        num_filters: 160\r\n      }\r\n      conv_hyperparams {\r\n        force_use_bias: true\r\n        activation: SWISH\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          scale: true,\r\n          decay: 0.99,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid_focal {\r\n          alpha: 0.25\r\n          gamma: 1.5\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    normalize_loc_loss_by_codesize: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.5\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  fine_tune_checkpoint: \"/API/Tensorflow/models/research/object_detection/test_data/efficientnet_b3/efficientnet_b3/ckpt-0\"\r\n  fine_tune_checkpoint_version: V2\r\n  fine_tune_checkpoint_type: \"classification\"\r\n  batch_size: 2\r\n  sync_replicas: true\r\n  startup_delay_steps: 0\r\n  replicas_to_aggregate: 8\r\n  use_bfloat16: false\r\n  num_steps: 600000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    random_scale_crop_and_pad_to_square {\r\n      output_size: 896\r\n      scale_min: 0.1\r\n      scale_max: 2.0\r\n    }\r\n  }\r\n  optimizer {\r\n    momentum_optimizer: {\r\n      learning_rate: {\r\n        cosine_decay_learning_rate {\r\n          learning_rate_base: 1e-2\r\n          total_steps: 600000\r\n          warmup_learning_rate: .001\r\n          warmup_steps: 2500\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n    }\r\n    use_moving_average: false\r\n  }\r\n  max_number_of_boxes: 100\r\n  unpad_groundtruth_tensors: false\r\n}\r\n\r\ntrain_input_reader: {\r\n  label_map_path: \"/DATASETS/COCO/classes.pbtxt\"\r\n  tf_record_input_reader {\r\n    input_path: \"/DATASETS/COCO/coco_train.record-00000-of-00100\"\r\n  }\r\n}\r\n\r\neval_config: {\r\n  metrics_set: \"coco_detection_metrics\"\r\n  use_moving_averages: false\r\n  batch_size: 1;\r\n}\r\n\r\neval_input_reader: {\r\n  label_map_path: \"/DATASETS/COCO/classes.pbtxt\"\r\n  shuffle: false\r\n  num_epochs: 1\r\n  tf_record_input_reader {\r\n    input_path: \"/DATASETS/COCO/coco_val.record-00000-of-00050\"\r\n  }\r\n}\r\n```\r\n\r\nAnd these are my results:\r\n![image](https://user-images.githubusercontent.com/75074147/157278088-cdb7bf3a-5edf-4233-9538-a0ff2a916536.png)\r\n![image](https://user-images.githubusercontent.com/75074147/157278121-9fdf037f-1497-42f3-8c17-1ed90902a0e3.png)\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10530/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10530/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10529","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10529/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10529/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10529/events","html_url":"https://github.com/tensorflow/models/issues/10529","id":1162797860,"node_id":"I_kwDOAwv_Dc5FTuMk","number":10529,"title":"VGGish support for batch inference","user":{"login":"gabriben","id":37249800,"node_id":"MDQ6VXNlcjM3MjQ5ODAw","avatar_url":"https://avatars.githubusercontent.com/u/37249800?v=4","gravatar_id":"","url":"https://api.github.com/users/gabriben","html_url":"https://github.com/gabriben","followers_url":"https://api.github.com/users/gabriben/followers","following_url":"https://api.github.com/users/gabriben/following{/other_user}","gists_url":"https://api.github.com/users/gabriben/gists{/gist_id}","starred_url":"https://api.github.com/users/gabriben/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/gabriben/subscriptions","organizations_url":"https://api.github.com/users/gabriben/orgs","repos_url":"https://api.github.com/users/gabriben/repos","events_url":"https://api.github.com/users/gabriben/events{/privacy}","received_events_url":"https://api.github.com/users/gabriben/received_events","type":"User","site_admin":false},"labels":[{"id":473246400,"node_id":"MDU6TGFiZWw0NzMyNDY0MDA=","url":"https://api.github.com/repos/tensorflow/models/labels/type:feature","name":"type:feature","color":"50bcc4","default":false,"description":""},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"}],"state":"open","locked":false,"assignee":{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},"assignees":[{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},{"login":"saberkun","id":4873189,"node_id":"MDQ6VXNlcjQ4NzMxODk=","avatar_url":"https://avatars.githubusercontent.com/u/4873189?v=4","gravatar_id":"","url":"https://api.github.com/users/saberkun","html_url":"https://github.com/saberkun","followers_url":"https://api.github.com/users/saberkun/followers","following_url":"https://api.github.com/users/saberkun/following{/other_user}","gists_url":"https://api.github.com/users/saberkun/gists{/gist_id}","starred_url":"https://api.github.com/users/saberkun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saberkun/subscriptions","organizations_url":"https://api.github.com/users/saberkun/orgs","repos_url":"https://api.github.com/users/saberkun/repos","events_url":"https://api.github.com/users/saberkun/events{/privacy}","received_events_url":"https://api.github.com/users/saberkun/received_events","type":"User","site_admin":false},{"login":"rachellj218","id":42055825,"node_id":"MDQ6VXNlcjQyMDU1ODI1","avatar_url":"https://avatars.githubusercontent.com/u/42055825?v=4","gravatar_id":"","url":"https://api.github.com/users/rachellj218","html_url":"https://github.com/rachellj218","followers_url":"https://api.github.com/users/rachellj218/followers","following_url":"https://api.github.com/users/rachellj218/following{/other_user}","gists_url":"https://api.github.com/users/rachellj218/gists{/gist_id}","starred_url":"https://api.github.com/users/rachellj218/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rachellj218/subscriptions","organizations_url":"https://api.github.com/users/rachellj218/orgs","repos_url":"https://api.github.com/users/rachellj218/repos","events_url":"https://api.github.com/users/rachellj218/events{/privacy}","received_events_url":"https://api.github.com/users/rachellj218/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2022-03-08T15:30:21Z","updated_at":"2022-03-11T20:02:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"## source\r\n\r\nhttps://github.com/tensorflow/models/tree/master/research/audioset/vggish\r\n\r\n## request\r\n\r\nWould it be possible to add a method to a VGGish model loaded from tensorhub to allow batch inference?\r\n\r\n## Additional context\r\n\r\nI am running this on millions of songs. I am also considering Ray or Apache beam to parallelize, but I assume it would be more efficient to allow the tensors themselves to accept batches. I am willing to contribute.","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10529/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10529/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10528","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10528/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10528/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10528/events","html_url":"https://github.com/tensorflow/models/issues/10528","id":1162053921,"node_id":"I_kwDOAwv_Dc5FQ4kh","number":10528,"title":"Retinanet evaluation spikes memory usage on TPUs, crashes training","user":{"login":"jacob-zietek","id":33991406,"node_id":"MDQ6VXNlcjMzOTkxNDA2","avatar_url":"https://avatars.githubusercontent.com/u/33991406?v=4","gravatar_id":"","url":"https://api.github.com/users/jacob-zietek","html_url":"https://github.com/jacob-zietek","followers_url":"https://api.github.com/users/jacob-zietek/followers","following_url":"https://api.github.com/users/jacob-zietek/following{/other_user}","gists_url":"https://api.github.com/users/jacob-zietek/gists{/gist_id}","starred_url":"https://api.github.com/users/jacob-zietek/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jacob-zietek/subscriptions","organizations_url":"https://api.github.com/users/jacob-zietek/orgs","repos_url":"https://api.github.com/users/jacob-zietek/repos","events_url":"https://api.github.com/users/jacob-zietek/events{/privacy}","received_events_url":"https://api.github.com/users/jacob-zietek/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1212020602,"node_id":"MDU6TGFiZWwxMjEyMDIwNjAy","url":"https://api.github.com/repos/tensorflow/models/labels/models:official","name":"models:official","color":"5319e7","default":false,"description":"models that come under official repository"}],"state":"open","locked":false,"assignee":{"login":"allenwang28","id":9057208,"node_id":"MDQ6VXNlcjkwNTcyMDg=","avatar_url":"https://avatars.githubusercontent.com/u/9057208?v=4","gravatar_id":"","url":"https://api.github.com/users/allenwang28","html_url":"https://github.com/allenwang28","followers_url":"https://api.github.com/users/allenwang28/followers","following_url":"https://api.github.com/users/allenwang28/following{/other_user}","gists_url":"https://api.github.com/users/allenwang28/gists{/gist_id}","starred_url":"https://api.github.com/users/allenwang28/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/allenwang28/subscriptions","organizations_url":"https://api.github.com/users/allenwang28/orgs","repos_url":"https://api.github.com/users/allenwang28/repos","events_url":"https://api.github.com/users/allenwang28/events{/privacy}","received_events_url":"https://api.github.com/users/allenwang28/received_events","type":"User","site_admin":false},"assignees":[{"login":"allenwang28","id":9057208,"node_id":"MDQ6VXNlcjkwNTcyMDg=","avatar_url":"https://avatars.githubusercontent.com/u/9057208?v=4","gravatar_id":"","url":"https://api.github.com/users/allenwang28","html_url":"https://github.com/allenwang28","followers_url":"https://api.github.com/users/allenwang28/followers","following_url":"https://api.github.com/users/allenwang28/following{/other_user}","gists_url":"https://api.github.com/users/allenwang28/gists{/gist_id}","starred_url":"https://api.github.com/users/allenwang28/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/allenwang28/subscriptions","organizations_url":"https://api.github.com/users/allenwang28/orgs","repos_url":"https://api.github.com/users/allenwang28/repos","events_url":"https://api.github.com/users/allenwang28/events{/privacy}","received_events_url":"https://api.github.com/users/allenwang28/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2022-03-07T23:44:06Z","updated_at":"2022-03-29T15:44:50Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Prerequisites\r\n\r\nPlease answer the following questions for yourself before submitting an issue.\r\n\r\n- [X] I am using the latest TensorFlow Model Garden release and TensorFlow 2.\r\n- [x] I am reporting the issue to the correct repository. (Model Garden official or research directory)\r\n- [X] I checked to make sure that this issue has not been filed already.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/blob/r2.8.0/official/vision/beta/train.py\r\nhttps://github.com/tensorflow/models/blob/r2.8.0/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tfds_tpu.yaml\r\n\r\n## 2. Describe the bug\r\n\r\nThere are exponentially increasing memory spikes on TPUs during the training and evaluation of Retinanet, this eventually causes a crash during training. This bug was found while working on the beta project [yolov4-tiny](https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/yolo). I observed that training needed to be restarted frequently, and there were thousands of lines of...\r\n```bash\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 290, in __del__\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 257, in destroy_resource_op\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 7186, in raise_from_not_ok_status\r\ntensorflow.python.framework.errors_impl.AbortedError: Unable to find a context_id matching the specified one (12469621923045235436). Perhaps the worker was restarted, or the context was GC'd? [Op:DestroyResourceOp]\r\nException ignored in: <function EagerResourceDeleter.__del__ at 0x7f58d152dc80>\r\n```\r\nin every training log file. Retinanet has the same issue. This crashing was observed on both v3-8 and v2-256 TPUs. \r\n\r\nThis bug is apparent looking at both the training output file (stderr and stdout) and the GCP TPU Dashboard charts. The output file shows the crash happening during evaluation, and the spikes in memory on the GCP TPU Dashboard occur only during evaluation. I provide the logs and pictures of the TPU memory usage in additional content. This bug was observed in \"train_and_eval\" mode, it does not occur in \"train\" mode.\r\n\r\n## 3. Steps to reproduce\r\n\r\nCreate a v3-8 TPU with version 2.8.0.\r\n\r\nLoad and SSH into a new GCP Compute Engine VM with the disk image Debian GNU/Linux 10 Buster + TF 2-8-0.\r\n\r\n`git clone https://github.com/tensorflow/models.git`\r\n`cd models`\r\n`git checkout r2.8.0`\r\n`pip3 install -r official/requirements.txt`\r\n\r\nInstall the COCO dataset, I used a GCP Bucket to store mine.\r\n\r\nModify the `official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tfds_tpu.yaml` config to use your COCO dataset instead of tfds (I did this because it was already installed in one of my buckets). It should look like...\r\n```yaml\r\nruntime:\r\n  distribution_strategy: 'tpu'\r\n  mixed_precision_dtype: 'bfloat16'\r\ntask:\r\n  annotation_file: ''  # Can't use annotation file when tfds is used.\r\n  losses:\r\n    l2_weight_decay: 0.0001\r\n  model:\r\n    num_classes: 91\r\n    max_level: 7\r\n    min_level: 3\r\n    input_size: [640, 640, 3]\r\n    norm_activation:\r\n      activation: relu\r\n      norm_epsilon: 0.001\r\n      norm_momentum: 0.99\r\n      use_sync_bn: true\r\n  train_data:\r\n          #tfds_name: 'coco/2017'\r\n          #tfds_split: 'train'\r\n    drop_remainder: true\r\n    dtype: bfloat16\r\n    global_batch_size: 256\r\n    input_path: 'gs://cam2-datasets/coco/train*'\r\n    is_training: true\r\n    shuffle_buffer_size: 1000\r\n  validation_data:\r\n          #tfds_name: 'coco/2017'\r\n          #tfds_split: 'validation'\r\n    drop_remainder: true\r\n    dtype: bfloat16\r\n    global_batch_size: 8\r\n    input_path: 'gs://cam2-datasets/coco/val*'\r\n    is_training: false\r\n```\r\n\r\nIn `~/models` run the training script...\r\n```bash\r\nnohup python3 -m official.vision.beta.train --mode=train_and_eval --experiment=retinanet_resnetfpn_coco --model_dir={MODEL_DIR_HERE} --config_file=~/models/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tfds_tpu.yaml --tpu={TPU_NAME_HERE} > ../retinanet.txt &\r\n```\r\nmine looked like...\r\n```bash\r\nnohup python3 -m official.vision.beta.train --mode=train_and_eval --experiment=retinanet_resnetfpn_coco --model_dir=gs://cam2-models/new-yolov4-tiny/retinanet/ --config_file=/home/cam2tensorflow/working/models/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tfds_tpu.yaml --tpu=tf-yolo-1 > ../retinanet.txt &\r\n```\r\n\r\nYou will see in `../retinanet.txt` that the training crashes with errors, and on the TPU monitoring you should see exponentially increasing spikes in memory usage during evaluation.\r\n\r\n## 4. Expected behavior\r\n\r\nThe training should run all the way through without crashing due to memory issues on the TPU.\r\n\r\n## 5. Additional context\r\n\r\n[TPU Memory Usage in dashboard](https://docs.google.com/document/d/1WKlZHJgPREk-uAT4COiGavF6n-EhfWbsTEFZsS5zors/edit?usp=sharing)\r\n[Retinanet training log after one crash](https://drive.google.com/file/d/1N2fYaeIDm9taQn3bvQ0ZQYtkfOt2MeY8/view?usp=sharing)\r\n\r\n## 6. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Debian 10.11\r\nDebian GNU/Linux 10 Buster + TF 2-8-0 Disk on GCP\r\n- TensorFlow installed from (source or binary): Pre-installed on disk\r\n- TensorFlow version (use command below): 2.8.0\r\n- Python version: 3.7.3\r\n\r\n<!-- \r\nCollect system information using our environment capture script.\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can also obtain the TensorFlow version with:\r\n\r\n1. TensorFlow 1.0\r\n`python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n\r\n2. TensorFlow 2.0\r\n`python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n-->\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10528/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10528/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10527","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10527/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10527/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10527/events","html_url":"https://github.com/tensorflow/models/issues/10527","id":1161939877,"node_id":"I_kwDOAwv_Dc5FQcul","number":10527,"title":"[Help] Run inference without box decoder and the preprocessor","user":{"login":"Mypathissional","id":29062197,"node_id":"MDQ6VXNlcjI5MDYyMTk3","avatar_url":"https://avatars.githubusercontent.com/u/29062197?v=4","gravatar_id":"","url":"https://api.github.com/users/Mypathissional","html_url":"https://github.com/Mypathissional","followers_url":"https://api.github.com/users/Mypathissional/followers","following_url":"https://api.github.com/users/Mypathissional/following{/other_user}","gists_url":"https://api.github.com/users/Mypathissional/gists{/gist_id}","starred_url":"https://api.github.com/users/Mypathissional/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Mypathissional/subscriptions","organizations_url":"https://api.github.com/users/Mypathissional/orgs","repos_url":"https://api.github.com/users/Mypathissional/repos","events_url":"https://api.github.com/users/Mypathissional/events{/privacy}","received_events_url":"https://api.github.com/users/Mypathissional/received_events","type":"User","site_admin":false},"labels":[{"id":473246506,"node_id":"MDU6TGFiZWw0NzMyNDY1MDY=","url":"https://api.github.com/repos/tensorflow/models/labels/type:support","name":"type:support","color":"abdd54","default":false,"description":""},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},"assignees":[{"login":"tombstone","id":126883,"node_id":"MDQ6VXNlcjEyNjg4Mw==","avatar_url":"https://avatars.githubusercontent.com/u/126883?v=4","gravatar_id":"","url":"https://api.github.com/users/tombstone","html_url":"https://github.com/tombstone","followers_url":"https://api.github.com/users/tombstone/followers","following_url":"https://api.github.com/users/tombstone/following{/other_user}","gists_url":"https://api.github.com/users/tombstone/gists{/gist_id}","starred_url":"https://api.github.com/users/tombstone/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tombstone/subscriptions","organizations_url":"https://api.github.com/users/tombstone/orgs","repos_url":"https://api.github.com/users/tombstone/repos","events_url":"https://api.github.com/users/tombstone/events{/privacy}","received_events_url":"https://api.github.com/users/tombstone/received_events","type":"User","site_admin":false},{"login":"jch1","id":1811449,"node_id":"MDQ6VXNlcjE4MTE0NDk=","avatar_url":"https://avatars.githubusercontent.com/u/1811449?v=4","gravatar_id":"","url":"https://api.github.com/users/jch1","html_url":"https://github.com/jch1","followers_url":"https://api.github.com/users/jch1/followers","following_url":"https://api.github.com/users/jch1/following{/other_user}","gists_url":"https://api.github.com/users/jch1/gists{/gist_id}","starred_url":"https://api.github.com/users/jch1/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jch1/subscriptions","organizations_url":"https://api.github.com/users/jch1/orgs","repos_url":"https://api.github.com/users/jch1/repos","events_url":"https://api.github.com/users/jch1/events{/privacy}","received_events_url":"https://api.github.com/users/jch1/received_events","type":"User","site_admin":false},{"login":"pkulzc","id":35853368,"node_id":"MDQ6VXNlcjM1ODUzMzY4","avatar_url":"https://avatars.githubusercontent.com/u/35853368?v=4","gravatar_id":"","url":"https://api.github.com/users/pkulzc","html_url":"https://github.com/pkulzc","followers_url":"https://api.github.com/users/pkulzc/followers","following_url":"https://api.github.com/users/pkulzc/following{/other_user}","gists_url":"https://api.github.com/users/pkulzc/gists{/gist_id}","starred_url":"https://api.github.com/users/pkulzc/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pkulzc/subscriptions","organizations_url":"https://api.github.com/users/pkulzc/orgs","repos_url":"https://api.github.com/users/pkulzc/repos","events_url":"https://api.github.com/users/pkulzc/events{/privacy}","received_events_url":"https://api.github.com/users/pkulzc/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2022-03-07T21:23:31Z","updated_at":"2022-03-08T12:50:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"Hi,\r\nI am trying to compare the ONNX predictions vs original model predictions. The main problem for me is that I need only the cut version of ONNX model and that is why I need to run the partial inference.\r\nIn Tensorflow v1 it was possible to get tensor by name, so doing the inference in the intermediate layers was easier but I don't understand how to do it in hee.\r\n\r\n Below I attach the ONNX generation script. How can I do the equivalent inference with saved_model in TensorFlow for this part of the graph (without box decoder and the preprocessor)?\r\n```\r\npython -m tf2onnx.convert --opset 12 --output \"./model.onnx\" --saved-model ./saved_model --inputs-as-nchw \"StatefulPartitionedCall/Preprocessor/stack:0\" --inputs \"StatefulPartitionedCall/Preprocessor/stack:0[1,640,640,3]\" --outputs StatefulPartitionedCall/concat_1:0,StatefulPartitionedCall/concat:0\r\n```\r\nWould be very grateful for any help,\r\nBest Regards\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10527/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10527/timeline","performed_via_github_app":null},{"url":"https://api.github.com/repos/tensorflow/models/issues/10526","repository_url":"https://api.github.com/repos/tensorflow/models","labels_url":"https://api.github.com/repos/tensorflow/models/issues/10526/labels{/name}","comments_url":"https://api.github.com/repos/tensorflow/models/issues/10526/comments","events_url":"https://api.github.com/repos/tensorflow/models/issues/10526/events","html_url":"https://github.com/tensorflow/models/issues/10526","id":1160722459,"node_id":"I_kwDOAwv_Dc5FLzgb","number":10526,"title":"Model trained with gpu is not as good as trained by cpu.","user":{"login":"springile","id":50204931,"node_id":"MDQ6VXNlcjUwMjA0OTMx","avatar_url":"https://avatars.githubusercontent.com/u/50204931?v=4","gravatar_id":"","url":"https://api.github.com/users/springile","html_url":"https://github.com/springile","followers_url":"https://api.github.com/users/springile/followers","following_url":"https://api.github.com/users/springile/following{/other_user}","gists_url":"https://api.github.com/users/springile/gists{/gist_id}","starred_url":"https://api.github.com/users/springile/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/springile/subscriptions","organizations_url":"https://api.github.com/users/springile/orgs","repos_url":"https://api.github.com/users/springile/repos","events_url":"https://api.github.com/users/springile/events{/privacy}","received_events_url":"https://api.github.com/users/springile/received_events","type":"User","site_admin":false},"labels":[{"id":473245893,"node_id":"MDU6TGFiZWw0NzMyNDU4OTM=","url":"https://api.github.com/repos/tensorflow/models/labels/type:bug","name":"type:bug","color":"FF4500","default":false,"description":"Bug in the code"},{"id":1213354216,"node_id":"MDU6TGFiZWwxMjEzMzU0MjE2","url":"https://api.github.com/repos/tensorflow/models/labels/models:research","name":"models:research","color":"FFFF00","default":false,"description":"models that come under research directory"},{"id":3117595031,"node_id":"MDU6TGFiZWwzMTE3NTk1MDMx","url":"https://api.github.com/repos/tensorflow/models/labels/models:research:odapi","name":"models:research:odapi","color":"D4A0E6","default":false,"description":"ODAPI"}],"state":"open","locked":false,"assignee":{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},"assignees":[{"login":"jaeyounkim","id":346043,"node_id":"MDQ6VXNlcjM0NjA0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/346043?v=4","gravatar_id":"","url":"https://api.github.com/users/jaeyounkim","html_url":"https://github.com/jaeyounkim","followers_url":"https://api.github.com/users/jaeyounkim/followers","following_url":"https://api.github.com/users/jaeyounkim/following{/other_user}","gists_url":"https://api.github.com/users/jaeyounkim/gists{/gist_id}","starred_url":"https://api.github.com/users/jaeyounkim/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/jaeyounkim/subscriptions","organizations_url":"https://api.github.com/users/jaeyounkim/orgs","repos_url":"https://api.github.com/users/jaeyounkim/repos","events_url":"https://api.github.com/users/jaeyounkim/events{/privacy}","received_events_url":"https://api.github.com/users/jaeyounkim/received_events","type":"User","site_admin":false},{"login":"saberkun","id":4873189,"node_id":"MDQ6VXNlcjQ4NzMxODk=","avatar_url":"https://avatars.githubusercontent.com/u/4873189?v=4","gravatar_id":"","url":"https://api.github.com/users/saberkun","html_url":"https://github.com/saberkun","followers_url":"https://api.github.com/users/saberkun/followers","following_url":"https://api.github.com/users/saberkun/following{/other_user}","gists_url":"https://api.github.com/users/saberkun/gists{/gist_id}","starred_url":"https://api.github.com/users/saberkun/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/saberkun/subscriptions","organizations_url":"https://api.github.com/users/saberkun/orgs","repos_url":"https://api.github.com/users/saberkun/repos","events_url":"https://api.github.com/users/saberkun/events{/privacy}","received_events_url":"https://api.github.com/users/saberkun/received_events","type":"User","site_admin":false},{"login":"rachellj218","id":42055825,"node_id":"MDQ6VXNlcjQyMDU1ODI1","avatar_url":"https://avatars.githubusercontent.com/u/42055825?v=4","gravatar_id":"","url":"https://api.github.com/users/rachellj218","html_url":"https://github.com/rachellj218","followers_url":"https://api.github.com/users/rachellj218/followers","following_url":"https://api.github.com/users/rachellj218/following{/other_user}","gists_url":"https://api.github.com/users/rachellj218/gists{/gist_id}","starred_url":"https://api.github.com/users/rachellj218/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/rachellj218/subscriptions","organizations_url":"https://api.github.com/users/rachellj218/orgs","repos_url":"https://api.github.com/users/rachellj218/repos","events_url":"https://api.github.com/users/rachellj218/events{/privacy}","received_events_url":"https://api.github.com/users/rachellj218/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2022-03-06T21:36:06Z","updated_at":"2022-03-12T21:02:06Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"body":"# Prerequisites\r\n\r\nPlease answer the following questions for yourself before submitting an issue.\r\n\r\n- [Yes ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.\r\n- [ ] I am reporting the issue to the correct repository. (Model Garden official or research directory)\r\n- [ ] I checked to make sure that this issue has not been filed already.\r\n\r\n## 1. The entire URL of the file you are using\r\n\r\nhttps://github.com/tensorflow/models/tree/master/official/...\r\n\r\n## 2. Describe the bug\r\n\r\nI want train a new model with ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.\r\n\r\nModel trained by CPU is better than GPU.\r\n\r\nFor the same picture, model trained by cpu can detect the object, but model from gpu can not.\r\n\r\ngpu:\r\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\r\n\r\ncpu:\r\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\r\n\r\n## 3. Steps to reproduce\r\n\r\nSteps to reproduce the behavior.\r\n\r\n## 4. Expected behavior\r\n\r\nModel trained by GPU should be the same as trained by CPU.\r\n\r\n## 6. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.8\r\n- Python version: 3.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 8.1\r\n- GPU model and memory: 16G\r\n\r\n","reactions":{"url":"https://api.github.com/repos/tensorflow/models/issues/10526/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/tensorflow/models/issues/10526/timeline","performed_via_github_app":null}]